#+TITLE: ABDUCTIO Recursive MECE Extension
#+SUBTITLE: White Paper Additions for Multi-Level Hypothesis Sets
#+DATE: December 21, 2025

* WHITE PAPER ADDITIONS FOR RECURSIVE MECE SETS

This document contains the sections to ADD to the ABDUCTIO MVP white paper to 
support recursive MECE hypothesis sets (nodes that own their own ledgers).

Insert these sections in the order shown, after the base MVP specification.

================================================================================

* 20. Recursive MECE Sets Extension

** 20.1 Motivation

In many domains, uncertainty lives not in a single requirement but in *which 
scenario characterizes that requirement*. For example:

- Within "Germany will grow" → "external environment" slot, we don't just 
  want to assess "external environment is favorable" as a single p value.
- We want to model: "External environment could be {improving, stable, 
  deteriorating, other}" and evaluate each scenario symmetrically.

This is fundamentally different from AND/OR decomposition of requirements:
- AND/OR: "This requirement breaks into parts X, Y, Z"
- MECE set: "This factor could manifest as scenarios A, B, or C"

** 20.2 Extension Overview

A node can spawn a *local MECE set* (subproblem) with:
- Its own scope (what the scenarios are about)
- Named scenario hypotheses + local H_other
- A local ledger (probability distribution over scenarios)
- Optional template obligations for each scenario
- Deterministic roll-up: parent node p = sum of satisfying scenarios

This enables:
1) Explicit modeling of nested uncertainties
2) Protection against vagueness at arbitrary depth
3) Symmetric evaluation of competing scenarios
4) Preservation of permutation invariance at every level

** 20.3 When to Use Recursive MECE vs AND/OR

Use AND/OR decomposition when:
- A requirement naturally breaks into multiple necessary parts
- The parts are conjunctive (all must hold)
- Example: "Export capacity" = "Manufacturing exists" AND "Trade routes open"

Use recursive MECE when:
- Uncertainty is about *which scenario applies*
- Scenarios are mutually exclusive alternatives
- You want to evaluate each scenario fairly before deciding
- Example: "External environment in 2026" could be {improving, stable, 
  deteriorating} — these are distinct alternatives, not requirements

** 20.4 Design Constraints (Permutation Invariance + Credit Boundedness)

To preserve core ABDUCTIO guarantees:

1) *Permutation invariance at every level*
   - Local hypothesis sets use canonical ordering
   - Roll-up rule is deterministic and order-independent
   - Frontier definition works the same way recursively

2) *Credit budgets prevent infinite descent*
   - Maximum depth limit (MVP: 2 levels)
   - β fraction rule: a root may spend at most β of its credits on 
     subproblems (default β=0.5)
   - Operations inside subproblems count against root's budget

3) *No probability laundering*
   - Local ledgers don't "create" probability
   - Parent p is a deterministic function of local ledger
   - Roll-up respects no-free-probability principle

================================================================================

* 21. Extended Data Model

** 21.1 Node with Subproblem Capability

Extend the Node dataclass from Section 4.1:

#+begin_src python
@dataclass
class Node:
    id: str
    statement: str
    p: float = 1.0
    k: float = 0.15
    
    # ... existing fields (role, children, decomp_type, coupling, etc.) ...
    
    # NEW: Recursive MECE capability
    subproblem: Optional["MECESet"] = None
    satisfying_scenario_ids: List[str] = field(default_factory=list)
    
    # Track which decomposition kind this is
    # decomp_type: Optional[str]  # "AND", "OR", "MECE_SET", "NONE"
#+end_src

** 21.2 MECESet (Reusable at Any Level)

Define a structure that can represent the top-level hypothesis set OR a local set:

#+begin_src python
@dataclass
class MECESet:
    """
    A MECE hypothesis partition at any depth.
    Can be the root session set or a local subproblem.
    """
    scope: str                              # What this set partitions
    roots: Dict[str, RootHypothesis]        # Named hypotheses + H_other
    ledger: Dict[str, float]                # Probability distribution
    
    # Parent context (None for top-level sets)
    parent_node_key: Optional[str] = None
    
    # Credit tracking at this level
    credits_spent: int = 0
#+end_src

** 21.3 Session Structure

Update EvaluationSession to support hierarchical sets:

#+begin_src python
@dataclass
class EvaluationSession:
    scope: str                      # Top-level question
    root_set: MECESet               # The main hypothesis set
    config: SessionConfig
    credits_budget: int
    
    # Registry of all MECE sets (flat map for easy lookup)
    all_sets: Dict[str, MECESet] = field(default_factory=dict)
    # Key format: "" for root, "H1:feasibility:c1" for nested
#+end_src

** 21.4 Key Invariants

For every MECESet at any level:
- Ledger sums to 1.0: \(\sum_{h \in \text{roots}} p_{\text{ledger}}(h) = 1.0\)
- Contains exactly one H_other
- All named hypotheses have exclusion clauses
- If parent_node_key is set, there exists a satisfying_scenario_ids list

================================================================================

* 22. Operations Extended

** 22.1 Three Decomposition Types

Extend the decomposition taxonomy from Section 5:

1) *DECOMPOSE_REQUIREMENTS(target)*: 1 credit
   - Creates AND/OR children (existing behavior)
   - Returns: {type: "AND"|"OR", coupling: float, children: [...]}

2) *SPAWN_MECE_SET(target)*: 1 credit (NEW)
   - Creates a local MECE hypothesis set under target node
   - Returns: {type: "MECE_SET", scope: str, scenarios: [...], 
              satisfying_ids: [...]}\n
3) *EVALUATE(target)*: 1 credit (unchanged)

** 22.2 SPAWN_MECE_SET Specification

Input: node_key (e.g., "H1:feasibility:external_env")

Output schema:
#+begin_src json
{
  "kind": "mece_set",
  "ok": true,
  "scope": "External economic environment for Germany in 2026",
  "scenarios": [
    {
      "id": "s_improve",
      "statement": "External environment improves significantly",
      "exclusion_clause": "Not stable or deteriorating"
    },
    {
      "id": "s_stable", 
      "statement": "External environment remains stable",
      "exclusion_clause": "Not improving or deteriorating"
    },
    {
      "id": "s_deteriorate",
      "statement": "External environment deteriorates",
      "exclusion_clause": "Not stable or improving"
    }
  ],
  "satisfying_ids": ["s_improve", "s_stable"],
  "other_statement": "Other external scenario"
}
#+end_src

Interpretation:
- `scope`: What the local MECE set is about
- `scenarios`: Named hypotheses for this subproblem
- `satisfying_ids`: Which scenarios satisfy the parent node's requirement
- If s_improve has p=0.5 and s_stable has p=0.3 in local ledger, then 
  parent node gets p = 0.5 + 0.3 = 0.8

** 22.3 Cost Accounting

All operations inside a subproblem count against the root hypothesis's budget:
- Root H1 has 10 credits allocated
- Spawning "H1:feasibility:external_env" subproblem costs 1 credit from H1
- Evaluating scenario "s_improve" costs 1 credit from H1
- When H1's credits exhaust, all its subproblems stop

================================================================================

* 23. Roll-Up Semantics (Critical)

** 23.1 The Roll-Up Problem

When a node owns a subproblem, how does the local ledger map to parent node p?

The parent node represents a requirement like "external environment is 
favorable." The local MECE set models *which scenario characterizes the 
environment*. Some scenarios satisfy the parent requirement, others violate it.

** 23.2 Deterministic Roll-Up Rule

Let node N with statement S own a local MECE set M with ledger L.

At spawn time, the decomposer specifies:
- satisfying_scenario_ids: List[str]  
  (which scenarios cause S to be true)

Roll-up function:
\[
p(N) = \sum_{s \in \text{satisfying\_scenario\_ids}} p_L(s)
\]

where \(p_L(s)\) is the ledger probability of scenario s in M.

** 23.3 Example

Node: "H1:feasibility:external_env" with statement "External environment 
      supports growth"

Subproblem M:
- Ledger: {s_improve: 0.5, s_stable: 0.3, s_deteriorate: 0.1, local_other: 0.1}
- satisfying_ids: ["s_improve", "s_stable"]

Roll-up: p(external_env) = 0.5 + 0.3 = 0.8

Interpretation: "There's an 80% chance the external environment satisfies this 
requirement, composed of 50% improving and 30% stable scenarios."

** 23.4 Confidence Roll-Up

Parent node confidence is the minimum k over scenarios that contribute 
meaningfully to parent p:

Define TopMass(satisfying_ids) = smallest subset of satisfying scenarios whose 
total probability is ≥ 80% of p(N).

Then:
\[
k(N) = \min_{s \in \text{TopMass}} k(s)
\]

This is conservative: parent confidence is only as high as the weakest scenario 
that materially contributes.

** 23.5 Invariants

1) Roll-up is *purely additive* over satisfying scenarios
   - No double-counting
   - No probability multiplication (that's for AND decomposition)

2) Roll-up is *deterministic*
   - Same local ledger → same parent p
   - Permutation-invariant: order of scenarios doesn't matter

3) satisfying_ids is *fixed at spawn*
   - Cannot change during evaluation
   - Must be auditable and reproducible

4) Local H_other contributes to parent p only if in satisfying_ids
   - Usually not included (conservative)
   - Can be included if "unknown scenario might still satisfy requirement"

================================================================================

* 24. Hierarchical Scheduling

** 24.1 Extended Frontier Definition

The frontier now operates at multiple levels:

Top-level frontier (unchanged):
\[
F_{\text{root}} = \{H_i : p_{\text{ledger}}(H_i) \ge p_{\text{leader}} - \varepsilon\}
\]

For each root in frontier, if it has active subproblems, define a *subproblem 
frontier* for each local MECE set using the same rule on the local ledger.

** 24.2 Credit Allocation Policy (β Rule)

To prevent infinite descent into subproblems:

**Rule**: A root hypothesis may spend at most β fraction of its total credits 
on subproblem operations before returning to top-level operations.

Default β = 0.5 (half its budget can go to nested evaluation)

Implementation:
- Track credits_in_subproblems counter per root
- Before entering subproblem: check credits_in_subproblems < β × total_credits
- If at limit: must perform top-level operation instead

** 24.3 Deterministic Operation Selection (Extended)

For a root H_i in top-level frontier:

1) If UNSCOPED or missing template slots: DECOMPOSE (root scoping)

2) Else: select slot s with lowest k

3) If slot s has subproblem M:
   a) If credits_in_subproblems < β × total_credits:
      - Compute frontier within M
      - Select operation within M (recursive application of same rules)
      - Increment credits_in_subproblems
   b) Else:
      - Must evaluate slot s directly or pick different slot

4) Else if slot s can spawn subproblem and k(s) < τ and depth < max_depth:
   - SPAWN_MECE_SET(s)

5) Else if slot s can decompose requirements and k(s) < τ:
   - DECOMPOSE_REQUIREMENTS(s)

6) Else:
   - EVALUATE(s) or EVALUATE(child of s)

** 24.4 Depth Limits

Hard constraint: max_depth (MVP default: 2)

Depth counting:
- Top-level roots: depth 0
- Subproblem spawned from root slot: depth 1
- Subproblem spawned from depth-1 scenario slot: depth 2

Once max_depth reached, SPAWN_MECE_SET is not allowed; only EVALUATE or 
DECOMPOSE_REQUIREMENTS.

** 24.5 Canonical Ordering in Subproblems

Within each local MECE set M:
- Scenarios ordered by canonical_id(statement)
- Tie-breaking uses same SHA256 hash approach as top level
- This preserves permutation invariance: renaming or reordering scenarios 
  doesn't change which operations are selected

================================================================================

* 25. Ledger Updates with Multi-Level Sets

** 25.1 Local Ledger Updates

Each MECE set maintains its own ledger independently.

When a scenario h_s within local set M is updated:

1) Compute p_prop(h_s) from its template obligations (same as root level)

2) Apply damping:
   \[
   p_{\text{ledger}}'(h_s) = (1-\alpha) p_{\text{ledger}}(h_s) + \alpha \cdot p_{\text{prop}}(h_s)
   \]

3) Enforce local H_other absorber:
   \[
   p_{\text{ledger}}(H_{\text{other}}^M) = 1 - \sum_{s \in \text{named scenarios}} p_{\text{ledger}}'(s)
   \]

4) Roll up to parent node:
   \[
   p(\text{parent}) = \sum_{s \in \text{satisfying\_ids}} p_{\text{ledger}}'(s)
   \]

5) Parent node's p change triggers re-aggregation of parent's slot, which 
   may trigger root ledger update

** 25.2 Cascading Updates

Updates propagate upward:

Level 2 scenario evaluated → local ledger updated → parent node p updated
→ Level 1 slot aggregated → Level 1 scenario ledger updated (if that node is 
also a scenario) → parent node p updated
→ Root template aggregated → root ledger updated

This is deterministic and auditable: every update is logged with explicit 
before/after values at each level.

** 25.3 Audit Trail for Multi-Level

New audit event types:

- SUBPROBLEM_SPAWNED:
  {parent_node_key, scope, scenario_ids, satisfying_ids}

- LOCAL_LEDGER_UPDATED:
  {mece_set_key, scenario_id, p_before, p_after}

- ROLL_UP_COMPUTED:
  {parent_node_key, satisfying_scenarios, contributions, p_parent}

- SUBPROBLEM_CREDITS_TRACKED:
  {root_id, credits_in_subproblems, beta_fraction, limit}

================================================================================

* 26. Template Obligations for Nested Scenarios (Optional)

** 26.1 Full Template vs Simplified Template

Decision: Should scenarios in a subproblem have the same 4-slot template as 
top-level roots?

Option A: *Full template* (rigorous)
- Each scenario gets: feasibility, availability, fit, defeater_resistance
- Pro: Maximum symmetry and rigor
- Con: Combinatorial explosion of credits

Option B: *Simplified template* (pragmatic)
- Scenarios get 1-2 slots: "plausibility" and maybe "evidence quality"
- Pro: Credit-efficient
- Con: Less symmetric scrutiny

Option C: *No template* (minimal)
- Scenarios evaluated directly as single nodes
- Pro: Simplest
- Con: Scenarios can remain vague

Recommendation: *Option B with configurable template*
- Default subproblem template: {plausibility: NEC, evidence: NEC}
- Allow override to full template if credits permit

** 26.2 Implementation Note

Each MECESet can have a template_config field:

#+begin_src python
@dataclass
class MECESet:
    # ... existing fields ...
    template_slots: List[str] = field(default_factory=lambda: ["plausibility"])
#+end_src

Top-level uses ["feasibility", "availability", "fit", "defeater_resistance"]
Depth-1 subproblems use ["plausibility"]
Depth-2 subproblems (if allowed) use [] (direct evaluation only)

================================================================================

* 27. Decomposer Contract Extended

** 27.1 Tagged Union Output

The decomposer must now return one of three schemas:

#+begin_src json
// Root scoping (unchanged)
{
  "kind": "scope_root",
  "ok": true,
  "feasibility_statement": "...",
  "availability_statement": "...",
  "fit_statement": "...",
  "defeater_statement": "..."
}

// Requirement decomposition (unchanged)
{
  "kind": "requirements",
  "ok": true,
  "type": "AND",
  "coupling": 0.80,
  "children": [
    {"child_id": "c1", "statement": "...", "role": "NEC"},
    {"child_id": "c2", "statement": "...", "role": "NEC"}
  ]
}

// Subproblem spawn (NEW)
{
  "kind": "mece_set",
  "ok": true,
  "scope": "What the scenarios are about",
  "scenarios": [
    {"id": "s1", "statement": "...", "exclusion_clause": "..."},
    {"id": "s2", "statement": "...", "exclusion_clause": "..."}
  ],
  "satisfying_ids": ["s1"],
  "other_statement": "Other scenario"
}
#+end_src

** 27.2 Decomposer Prompt Guidance

When calling decomposer for a node that could spawn a subproblem:

System prompt should include:
"""
You may return either:
1) Requirement decomposition (AND/OR of necessary conditions)
2) MECE scenario set (mutually exclusive alternative characterizations)

Use (2) when:
- The node represents a factor that could manifest in distinct ways
- Those ways are mutually exclusive (can't both be true)
- You want to evaluate each way symmetrically before deciding

Provide satisfying_ids: which scenarios cause the parent node to be satisfied.
"""

** 27.3 Validation

The engine must validate:
- scenarios list has 2-5 entries
- All scenario IDs are unique
- All exclusion clauses are non-empty
- satisfying_ids ⊆ scenario IDs
- scope is non-empty

If validation fails: treat as decomposition failure (ok: false)

================================================================================

* 28. Stopping Conditions Extended

Extend Section 14 stopping conditions:

Stop when:

A) Credits exhausted (unchanged)

B) *Frontier confident at all active levels*:
   - Top-level frontier roots are SCOPED with all slots k ≥ τ
   - AND: For each active subproblem whose parent node is in a frontier 
     hypothesis, the subproblem's own frontier is confident OR credits 
     prevent further improvement

C) No legal next operation (unchanged, but check recursively)

D) β limit reached and no top-level operations improve confidence

================================================================================

* 29. Implementation Checklist

To add recursive MECE to an existing ABDUCTIO MVP implementation:

1) *Data model changes*:
   - [ ] Add Node.subproblem: Optional[MECESet]
   - [ ] Add Node.satisfying_scenario_ids: List[str]
   - [ ] Make MECESet reusable (add parent_node_key, template_slots)
   - [ ] Add session.all_sets registry

2) *Operation changes*:
   - [ ] Add SPAWN_MECE_SET to cost model
   - [ ] Update decomposer contract to return tagged union
   - [ ] Add validation for mece_set decomposition output

3) *Scheduling changes*:
   - [ ] Implement β fraction tracking per root
   - [ ] Add recursive frontier computation
   - [ ] Update _legal_next_for_root to check subproblems
   - [ ] Add depth tracking and max_depth enforcement

4) *Roll-up logic*:
   - [ ] Implement deterministic satisfying_scenarios sum
   - [ ] Implement TopMass k aggregation
   - [ ] Add cascading update propagation

5) *Audit trail*:
   - [ ] Add SUBPROBLEM_SPAWNED event
   - [ ] Add LOCAL_LEDGER_UPDATED event
   - [ ] Add ROLL_UP_COMPUTED event
   - [ ] Add SUBPROBLEM_CREDITS_TRACKED event

6) *Replay support*:
   - [ ] Extend replay to rebuild subproblem structure
   - [ ] Verify cascading updates replay correctly

================================================================================

* 30. Example: Full Recursive Evaluation

** 30.1 Setup

Scope: "Germany's GDP trajectory in 2026"

Top-level hypotheses:
- H_grow: "Economy will grow"
- H_flat: "Economy will be flat"  
- H_shrink: "Economy will shrink"
- H_other: "Other trajectory"

** 30.2 Template for H_grow

Slots:
1. feasibility: "Growth is possible given constraints"
2. availability: "Growth drivers are present"
3. fit: "Explains indicators better than rivals"
4. defeater_resistance: "Key defeaters don't apply"

** 30.3 Subproblem Spawn

Node: "H_grow:availability:external_env"
Statement: "External environment supports growth"

Decomposer returns:
#+begin_src json
{
  "kind": "mece_set",
  "scope": "External economic environment for Germany in 2026",
  "scenarios": [
    {
      "id": "env_improve",
      "statement": "External environment improves (EU recovery, trade boost)",
      "exclusion_clause": "Not stable or deteriorating"
    },
    {
      "id": "env_stable",
      "statement": "External environment remains stable",
      "exclusion_clause": "Not improving or deteriorating"
    },
    {
      "id": "env_deteriorate",
      "statement": "External environment deteriorates (recession, trade war)",
      "exclusion_clause": "Not stable or improving"
    }
  ],
  "satisfying_ids": ["env_improve", "env_stable"],
  "other_statement": "Other external scenario"
}
#+end_src

** 30.4 Local Ledger Evolution

Initial (uniform over 3 scenarios):
- env_improve: 0.27
- env_stable: 0.27
- env_deteriorate: 0.27
- local_H_other: 0.20

After evaluating scenarios (simplified template: just plausibility):
- env_improve: 0.35 (k=0.55)
- env_stable: 0.40 (k=0.75)
- env_deteriorate: 0.15 (k=0.70)
- local_H_other: 0.10

** 30.5 Roll-Up

Parent node: "H_grow:availability:external_env"
satisfying_ids: ["env_improve", "env_stable"]

Roll-up:
\[
p(\text{external\_env}) = 0.35 + 0.40 = 0.75
\]

TopMass = {env_stable, env_improve} (both contribute)
\[
k(\text{external\_env}) = \min(0.75, 0.55) = 0.55
\]

** 30.6 Impact on Root

This rolls up to H_grow:availability slot aggregation.

If availability has 3 children (external_env being one) with p = [0.75, 0.90, 0.85]:
\[
p(\text{availability}) = \text{soft\_AND}([0.75, 0.90, 0.85]) \approx 0.78
\]

Then availability contributes to root multiplier:
\[
m_{\text{grow}} = p_{\text{feasibility}} \times p_{\text{availability}} \times p_{\text{fit}} \times p_{\text{defeater}}
\]

** 30.7 Audit Trail

SUBPROBLEM_SPAWNED:
  parent_node_key: "H_grow:availability:external_env"
  scope: "External economic environment for Germany in 2026"
  scenario_ids: ["env_improve", "env_stable", "env_deteriorate"]
  satisfying_ids: ["env_improve", "env_stable"]

NODE_EVALUATED:
  node_key: "H_grow:availability:external_env::env_stable:plausibility"
  p: 0.80, k: 0.75

LOCAL_LEDGER_UPDATED:
  mece_set_key: "H_grow:availability:external_env"
  scenario_id: "env_stable"
  p_before: 0.27, p_after: 0.40

ROLL_UP_COMPUTED:
  parent_node_key: "H_grow:availability:external_env"
  satisfying_scenarios: {"env_improve": 0.35, "env_stable": 0.40}
  p_parent: 0.75, k_parent: 0.55

================================================================================

* 31. Practical Defaults for Recursive Extension

- max_depth: 2 (allow one level of subproblems)
- β fraction: 0.5 (half of credits can go to subproblems)
- subproblem_template: ["plausibility"] (simplified)
- min_scenarios: 2
- max_scenarios: 5 (same as other decomposition limits)
- subproblem_gamma: 0.15 (local H_other prior, slightly lower than top-level)

================================================================================

* 32. Why This Preserves Permutation Invariance

The recursive extension maintains permutation invariance because:

1) *Subproblem spawn is deterministic*
   - Triggered by same conditions (k < τ, depth < max, etc.)
   - Decomposer output is canonical (ordered by scenario statement hash)

2) *Local frontiers use canonical ordering*
   - Same frontier definition at every level
   - Same tie-breaking via canonical_id

3) *Roll-up is deterministic*
   - Purely additive over satisfying scenarios
   - Order of scenarios doesn't affect sum
   - k aggregation uses canonical TopMass ordering

4) *Credit allocation is fair*
   - β rule applies uniformly to all roots
   - Round-robin at each level preserves symmetry
   - No focal privilege in subproblem scheduling

5) *satisfying_ids fixed at spawn*
   - Can't be gamed by reordering
   - Part of decomposer output, not scheduler decision

Given identical inputs at every level, the same tree of MECE sets is constructed 
in the same canonical order, with identical roll-up values.

================================================================================

* 33. Limitations of Recursive Extension

1) *Depth limits required*
   - Prevents infinite regress
   - May force premature evaluation of deep uncertainties

2) *Independence assumption between subproblems*
   - Two different slots might depend on same latent factor
   - No cross-linking of subproblems in MVP extension
   - Future: shared factor graphs

3) *Credit allocation complexity*
   - β rule is heuristic, not optimal
   - May spend too much on one subproblem at expense of others
   - Future: EVSI-like credit allocation

4) *Template choice for scenarios*
   - Simplified templates reduce rigor
   - Full templates explode credit requirements
   - No principled way to choose intermediate

5) *satisfying_ids must be specified upfront*
   - Can't change based on evaluation results
   - Must be conservative (include uncertain scenarios in satisfying_ids)
   - Future: dynamic satisfying_ids updates with re-roll-up

================================================================================

* 34. Migration Path

For existing ABDUCTIO MVP implementations:

**Phase 1**: Add data structures (non-breaking)
- Extend Node with optional subproblem field
- All existing code treats subproblem=None (no change)

**Phase 2**: Add SPAWN_MECE_SET operation (opt-in)
- Decomposer can return "mece_set" kind
- Engine recognizes it and builds subproblem
- Old sessions with requirement-only decomposition still work

**Phase 3**: Update scheduler (transparent)
- Add β tracking and recursive frontier logic
- Only activates when subproblems exist
- Old sessions see no behavior change

**Phase 4**: Update audit/replay (backward compatible)
- Add new event types
- Old events replay unchanged
- New events ignored by old replay code

**Phase 5**: Update defaults and documentation
- Set max_depth=2, β=0.5 as defaults
- Provide examples and best practices

================================================================================

* 35. Summary of Additions to White Paper

New sections added:
- §20: Recursive MECE Sets Extension (motivation + overview)
- §21: Extended Data Model (Node.subproblem, MECESet, hierarchical session)
- §22: Operations Extended (SPAWN_MECE_SET)
- §23: Roll-Up Semantics (deterministic satisfying_scenarios sum)
- §24: Hierarchical Scheduling (β rule, recursive frontier)
- §25: Ledger Updates with Multi-Level Sets (cascading updates)
- §26: Template Obligations for Nested Scenarios (simplified templates)
- §27: Decomposer Contract Extended (tagged union)
- §28: Stopping Conditions Extended (recursive confidence checks)
- §29: Implementation Checklist
- §30: Example (full walkthrough)
- §31: Practical Defaults
- §32: Permutation Invariance Preservation
- §33: Limitations
- §34: Migration Path
- §35: Summary (this section)

Changes to existing sections:
- §4: Update data model to show Node.subproblem field
- §5: Add SPAWN_MECE_SET to cost model
- §14: Extend stopping conditions
- §15: Update decomposer contract
- §17: Add bullet about hierarchical PI

No changes needed to:
- §1-3: Motivation, PI definition, design principles (still valid)
- §6-13: Template, semantics, aggregation, ledger (work at every level)
- §16: Pseudocode (extend naturally with recursive calls)
- §18: Practical defaults (add new ones, keep existing)

================================================================================

END OF RECURSIVE MECE EXTENSION ADDITIONS
