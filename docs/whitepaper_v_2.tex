% Created 2026-01-11 Sun 13:39
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{amsmath,amssymb,amsthm}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newcommand{\clip}{\operatorname{clip}}
\newcommand{\logit}{\operatorname{logit}}
\newcommand{\RotDist}{d_{\mathrm{rot}}}
\usepackage{amsmath,amssymb,amsthm}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newcommand{\clip}{\operatorname{clip}}
\newcommand{\logit}{\operatorname{logit}}
\newcommand{\RotDist}{d_{\mathrm{rot}}}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\author{David Joseph (adaptable)}
\date{December 19, 2025}
\title{ABDUCTIO v2\\\medskip
\large Symmetric Evidence Updates, Anti-Inflation Aggregation, and VOI-Lite Scheduling}
\hypersetup{
 pdfauthor={David Joseph (adaptable)},
 pdftitle={ABDUCTIO v2},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 30.2 (Org mode 9.7.11)}, 
 pdflang={English}}
\begin{document}

\maketitle
\setcounter{tocdepth}{2}
\tableofcontents

\section{Abstract}
\label{sec:orgc5db41e}
ABDUCTIO v2 is a lightweight, domain-agnostic methodology for evaluating a mutually exclusive, collectively exhaustive (MECE) set of hypotheses under strict resource constraints. It eliminates focal privilege by enforcing permutation invariance: the output assigned to any hypothesis is independent of ordering or seed choice.

This revision strengthens inferential quality without adding Bayesian machinery: evidence updates are symmetric (up or down), aggregation avoids decomposition-driven inflation, and scheduling prioritizes uncertainty rather than "most likely." The result remains implementation-ready, credit-bounded, and fully auditable.
\section{1. Motivation and Problem}
\label{sec:orgcd400b6}
Many controversial evaluations fail for a structural reason:

\begin{itemize}
\item Hypothesis \(H^*\) (often "far-fetched") is decomposed into multiple subclaims.
\item Rival hypotheses \(R_i\) remain broad or underspecified.
\item Evidence undermining one subclaim of \(H^*\) shifts weight to rivals.
\item Rivals gain weight not because they are supported, but because they were not required to articulate necessary commitments.
\end{itemize}

This is not merely a cognitive bias--it is a systems design failure. If the procedure taxes some hypotheses with specificity and not others, it bakes in unfairness.

ABDUCTIO addresses this by requiring:
\begin{enumerate}
\item every hypothesis to be defined as a stand-alone mechanism, and
\item every hypothesis to be evaluated under the same obligation template and the same credit schedule, independent of ordering.
\end{enumerate}
\section{1.1 Scope vs Hypotheses: A Functional Distinction}
\label{sec:orga380f0b}
ABDUCTIO evaluates a MECE set of \textbf{hypotheses} about a \textbf{scope}. The scope is the
question, phenomenon, or case under evaluation - it defines what the hypothesis set
is partitioning. This is a \textbf{functional} distinction, not an ontological one.

Examples:

\begin{itemize}
\item \textbf{\textbf{Scope}}: "Germany's GDP trajectory in 2026"
\textbf{\textbf{Hypotheses}}: \{grow, flat, shrink, other\}

\item \textbf{\textbf{Scope}}: "Why did the Ariel School incident occur?"
\textbf{\textbf{Hypotheses}}: \{hoax, misidentified\textsubscript{aircraft}, shared\textsubscript{hallucination},
		 unknown\textsubscript{phenomenon}, other\}
\end{itemize}

The same statement can play different roles depending on the level of analysis.
"The economy will grow" is:
\begin{itemize}
\item A \textbf{hypothesis} when evaluating "What will happen to GDP?"
\item A \textbf{scope} when evaluating "Why would the economy grow?"
\end{itemize}

Without an explicit scope, MECE accounting becomes ambiguous: H\textsubscript{other} means
"other explanation of what?" The scope answers this question and makes audit
trails readable.
\section{2. Core Requirement: Permutation Invariance}
\label{sec:org3a8fbef}
\subsection{2.1 Informal statement}
\label{sec:orgec38241}
Given the same hypothesis set, the same evidence, and the same credit budget, the final \((p,k)\) assigned to any hypothesis must not depend on:
\begin{itemize}
\item which hypothesis was chosen as "focal,"
\item the order hypotheses are listed,
\item the order evaluation steps are printed.
\end{itemize}
\subsection{2.2 Formal statement}
\label{sec:orgc4c575e}
Let \(H=\{h_1,\dots,h_n\}\) be a MECE set in closed-world mode, or \(H=\{h_1,\dots,h_n,h_{\text{other}}\}\) in open-world mode. Let an engine \(F\) map:
\[
F(H,E,B,\theta) \mapsto \{(p(h_i),k(h_i))\}_{i=1}^n \cup (p(h_{\text{other}}),k(h_{\text{other}}))
\]
where \(E\) is evidence, \(B\) a credit budget, and \(\theta\) configuration parameters.

Permutation invariance requires that for any permutation \(\pi\) of the \textbf{named} hypotheses,
\[
F(H,E,B,\theta) = F(\pi(H),E,B,\theta)
\]
up to the same renaming/reordering of outputs.
\subsection{2.3 Design implications}
\label{sec:org6b37eae}
Permutation invariance forces three conditions:

\begin{enumerate}
\item \textbf{Semantic independence}: each hypothesis must be meaningful without reference to a "seed."
\item \textbf{Procedural symmetry}: credit allocation and stopping rules must not privilege any hypothesis.
\item \textbf{Determinism}: tie-breaking must not depend on presentation order.
\end{enumerate}

ABDUCTIO v2 implements all three.
\section{3. Design Principles}
\label{sec:orgbdcd821}
\subsection{P1. Stand-alone hypotheses}
\label{sec:orga280591}
Each named hypothesis must be describable without mentioning any other hypothesis. Prohibited: "NOT H1," "some mundane explanation," "any other cause," or umbrella OR-bundles as roots.
\subsection{P2. MECE + explicit Other (open-world mode)}
\label{sec:org997c512}
The set of named hypotheses is intended to be mutually exclusive (ME) and collectively exhaustive (CE). In open-world mode, collective exhaustiveness is implemented by including:
\begin{itemize}
\item \(H_{\text{other}}\): "Unknown/unmodeled explanation."
\end{itemize}
\subsection{P3. No-free-probability}
\label{sec:org427ba8f}
Listing more subcases must not increase a hypothesis's probability. Decomposition clarifies structure; it does not create credence.
\subsection{P4. Same burdens for all}
\label{sec:org82fb87a}
Each hypothesis is evaluated through a fixed \textbf{obligation template} (Section 6). This prevents one hypothesis from being saddled with "cosmic feasibility" while rivals face only local plausibility checks.
\subsection{P5. Credit-bounded termination}
\label{sec:org0581a0a}
Only two operations exist (Evaluate, Decompose), each costing 1 credit. The process halts by budget or by meeting confidence thresholds.
\subsection{P6. Fully auditable}
\label{sec:org3c87120}
Every update must be reproducible from logged arithmetic and rubric scoring. No "implicit" ledger shifts are allowed.
\section{4. Data Model}
\label{sec:org8f897b5}
\subsection{4.1 Hypothesis roots and nodes}
\label{sec:orgff6121f}
A hypothesis is represented as a root node with an obligation template and optional internal decomposition trees.

\begin{verbatim}
from dataclasses import dataclass, field
from typing import Optional, Literal, Dict, List, Tuple

Role = Literal["NEC", "EVID"]
DecompType = Literal["AND", "OR"]
ScopeMode = Literal["CLOSED_WORLD", "OPEN_WORLD"]

@dataclass
class EvaluationSession:
    """
    A scoped hypothesis evaluation run.

    The scope defines what the MECE hypothesis set is about.
    It's not itself a hypothesis - it's the frame for the partition.
    """
    scope: str                              # "Germany's 2026 GDP trajectory"
    hypothesis_set: HypothesisSet           # The MECE partition being evaluated
    config: SessionConfig                   # tau, epsilon, gamma, alpha, beta, W, lambda_voi, world_mode
    credits_budget: int                     # Total operations allowed

@dataclass
class Node:
    id: str
    statement: str

    # Local scores for this node (not ledger probability)
    p: float = 0.5          # neutral assessment for NEC/EVID
    k: float = 0.15

    # Audit
    k_rubric: Optional[Dict[str, int]] = None  # {"A":0..2,"B":0..2,"C":0..2,"D":0..2}
    evidence_ids: List[str] = field(default_factory=list)
    evidence_quality: Optional[str] = None     # "direct"|"indirect"|"weak"|"none"
    reasoning_summary: Optional[str] = None
    defeaters: List[str] = field(default_factory=list)
    uncertainty_source: Optional[str] = None
    assumptions: List[str] = field(default_factory=list)
    quotes: List[Dict[str, str]] = field(default_factory=list)

    # Decomposition
    role: Optional[Role] = None
    children: Dict[str, "Node"] = field(default_factory=dict)
    decomp_type: Optional[DecompType] = None

    # AND coupling for NEC children within a slot
    coupling: Optional[float] = None  # one of {0.20, 0.50, 0.80, 0.95}
    falsifiable: Optional[bool] = None
    test_procedure: Optional[str] = None
    overlap_with_siblings: List[str] = field(default_factory=list)

    # Accounting
    credits_spent: int = 0
    status: Optional[str] = None      # "SCOPED", "UNSCOPED"

@dataclass
class RootHypothesis:
    id: str
    statement: str
    exclusion_clause: str  # one line: what makes this not any other root

    # Ledger probability (MECE bookkeeping)
    p_ledger: float
    k_root: float = 0.15

# Obligation slots (fixed template; Section 6)
    obligations: Dict[str, Node] = field(default_factory=dict)

    # Audit
    credits_spent: int = 0

@dataclass
class HypothesisSet:
    roots: Dict[str, RootHypothesis]  # includes "H_other" only in open-world mode
\end{verbatim}
\subsection{4.2 Ledger invariants}
\label{sec:org71ba3ba}
Closed-world mode:
\begin{itemize}
\item \(p_{\text{ledger}}(h) \in [0,1]\)
\item \(\sum_{i=1}^n p_{\text{ledger}}(H_i) = 1\)
\end{itemize}

Open-world mode:
\begin{itemize}
\item named roots + \(H_{\text{other}}\) with \(\sum p_{\text{ledger}} = 1\)
\item \(H_{\text{other}}\) is a first-class hypothesis with its own ledger mass
\end{itemize}
\section{5. Cost Model}
\label{sec:org5db6629}
Only two operations exist.

\begin{itemize}
\item \texttt{DECOMPOSE(target)} : 1 credit
\item \texttt{EVALUATE(target)} : 1 credit
\end{itemize}

Everything else (aggregation, ledger enforcement, scheduling) is "free" but must be logged.
\section{6. Obligation Template (Permutation-Invariance Backbone)}
\label{sec:org4206d25}
Every named root hypothesis must be evaluated through the same template of obligation slots. This guarantees that each hypothesis faces comparable explanatory burdens.
\subsection{6.1 Required slots (default v2)}
\label{sec:org90e66d9}
Each root \(H_i\) must define four slots:

\begin{enumerate}
\item \textbf{Feasibility (general)} {[}NEC]
\begin{itemize}
\item The mechanism is possible in principle.
\end{itemize}
\item \textbf{Availability (context)} {[}NEC]
\begin{itemize}
\item The mechanism is present/available in the specific time/place/context.
\end{itemize}
\item \textbf{Fit to key features} {[}NEC]
\begin{itemize}
\item The mechanism explains the core reported observations better than at least one competitor.
\end{itemize}
\item \textbf{Defeater resistance} {[}NEC]
\begin{itemize}
\item The strongest competitor-specific defeater does not apply.
\end{itemize}
\end{enumerate}

These are expressed as NEC nodes. Additional EVID nodes are allowed but may not be used to inflate probability.
\subsection{6.2 Template customization}
\label{sec:orgf574083}
Implementations may add slots, but must:
\begin{itemize}
\item apply the same slots to all named roots, and
\item keep total slots small (4-7 recommended).
\end{itemize}
\subsection{6.3 Why this matters}
\label{sec:orge18312a}
Without a template, decomposition can be weaponized: one hypothesis can be loaded with "universal feasibility" while rivals get only vague local stories. Template parity removes this asymmetry.
\section{7. Semantics of p within trees ("No-free-probability")}
\label{sec:orgc7b769d}
ABDUCTIO v2 distinguishes \textbf{ledger probability} from \textbf{internal node p}:

\begin{itemize}
\item \(p_{\text{ledger}}(H_i)\): MECE bookkeeping probability over roots.
\item \(p(\text{NEC/EVID node})\): assessment score used to compute a bounded weight of evidence.
\end{itemize}
\subsection{7.1 Neutral defaults}
\label{sec:org17bea38}
Unassessed nodes do not move the ledger:
\begin{itemize}
\item NEC/EVID nodes initialize at \(p=0.5\) (neutral) with low \(k=0.15\).
\item Unassessed slots contribute \(w=0\) to ledger updates (Section 11).
\end{itemize}
\subsection{7.2 Consequence}
\label{sec:org5000768}
Decomposition cannot lower or raise a hypothesis merely by adding structure. Only evaluated requirements can move the ledger, and moves are symmetric (up or down). DECOMPOSE never changes ledger beliefs; it creates nodes with \(w=0\) until EVALUATE occurs.
\subsection{7.3 Delta-w ledger rule (no-free-probability enforcement)}
\label{sec:org0ade3fa}
Recomputing a node's aggregated \(p\) after decomposition must not move ledger mass without paying an EVALUATE credit. Maintain per-slot applied weights:

\begin{itemize}
\item \(w_{\text{applied}}[h,s]\): last evidence weight actually applied to the ledger.
\end{itemize}

Normative: Only an EVALUATE operation may change the ledger via a nonzero \(\Delta w\). DECOMPOSE MUST NOT change ledger probabilities.

When EVALUATE occurs for \((h,s)\):
\begin{itemize}
\item compute \(w_{\text{new}} = \mathrm{clip}(\beta k \cdot \mathrm{logit}(p), -W, W)\)
\item \(\Delta w = w_{\text{new}} - w_{\text{applied}}[h,s]\)
\item update \(\log p(h) \leftarrow \log p(h) + \Delta w\), then normalize
\item set \(w_{\text{applied}}[h,s] \leftarrow w_{\text{new}}\)
\end{itemize}

DECOMPOSE may change internal structure and displayed aggregated \(p\), but MUST NOT change \(w_{\text{applied}}\) or ledger \(p\) unless an EVALUATE credit is spent. Log \(w_{\text{old}}\), \(w_{\text{new}}\), \(\Delta w\), and normalization arithmetic.

If a required slot is decomposed, the engine may apply \(w\) using either:
\begin{itemize}
\item the slot node's own evaluation (if it exists), or
\item an aggregated \((p,k)\) from its decisive children,
\end{itemize}
but only after an EVALUATE credit and using the Delta-w mechanism.
\section{8. Confidence k: Rubric and Mapping}
\label{sec:org62f6c8e}
Confidence \(k\) is the stability/robustness of a credence estimate under reasonable re-checking.
\subsection{8.1 Rubric (0-2 each)}
\label{sec:orgfb327b3}
A: Evidence Traceability
B: Cross-Validation
C: Sensitivity to Assumptions
D: Adversarial Resilience

Total \(T=A+B+C+D\) maps to:

\begin{itemize}
\item 0-1 -> 0.15
\item 2-3 -> 0.35
\item 4-5 -> 0.55
\item 6-7 -> 0.75
\item 8 -> 0.90
\end{itemize}

Guardrail: if any check = 0, cap \(k \le 0.55\).
\subsection{8.2 Root confidence}
\label{sec:org96bb64d}
Root confidence \(k_{\text{root}}\) is defined deterministically as the minimum \(k\) over required NEC slots (conservative). If UNSCOPED, cap:
\[
k_{\text{root}} \le k_{\max}^{\text{UNSCOPED}}.
\]
Log the chosen rule and caps.
\subsection{8.3 k propagation through trees (deterministic, conservative)}
\label{sec:org7efb7ed}
When a slot is decomposed, parent \(k\) is derived deterministically:

\begin{itemize}
\item AND of NEC children (within a slot): \(k_{\text{parent}} = \min_j k_j\).
\item OR of EVID children: \(k_{\text{parent}} = k_{j^\ast}\) where \(j^\ast = \arg\max_j p_j\) (tie-break canonically).
\item UNSCOPED inheritance: if any child is UNSCOPED, cap \(k_{\text{parent}} \le 0.40\).
\item Rubric guardrail inheritance: if any child has any rubric check = 0 and that child is decisive for the parent (AND: any child; OR: the max-p child), cap \(k_{\text{parent}} \le 0.55\).
\end{itemize}

These rules are deterministic, easy to audit, and align with necessity vs sufficiency intuition.
\section{9. Decomposition Rules}
\label{sec:org2ffb059}
\subsection{9.1 Root scoping is mandatory}
\label{sec:orgbbbfa3f}
All named roots must be decomposed into the obligation template before any root can be accepted as "well-scrutinized."
\subsection{9.2 Additional decomposition within slots (optional)}
\label{sec:org45e3e6c}
Each slot node may be decomposed further (2-5 children) when its confidence is below threshold and credits remain.
\subsection{9.3 Coupling for AND nodes (within a slot)}
\label{sec:org00c7b3e}
When decomposing a slot into an AND of NEC children, choose coupling \(c \in \{0.20,0.50,0.80,0.95\}\) deterministically from overlap scores (Section 9.5).

Soft-AND for assessed children:
\[
p_{\text{AND}} = c \cdot p_{\min} + (1-c)\cdot p_{\prod}
\]
where \(p_{\min}\) and \(p_{\prod}\) are computed over assessed NEC children (unassessed treated as 0.5).
\subsection{9.4 OR aggregation (anti-inflationary)}
\label{sec:org2421aa1}
Default OR aggregator is max:
\[
p_{\text{OR}}=\max_j p_j
\]
Interpretation: a parent is supported at least as well as its strongest child.

Optional discounted noisy-OR (requires explicit overlap discount \(d\in(0,1]\)):
\[
p_{\text{noisy}} = 1 - \prod_j (1-p_j)^{d}
\]
\[
p_{\text{OR}} = \min\bigl(\max_j p_j,\; p_{\text{noisy}}\bigr)
\]
Higher overlap \(\Rightarrow\) smaller \(d\) \(\Rightarrow\) less inflation. The \(\min\) cap prevents noisy-OR from exceeding the strongest child unless explicitly removed.
\subsection{9.5 Overlap checklist to choose coupling}
\label{sec:org89a3cd2}
Score overlap on three rubric items (0-2 each):
\begin{itemize}
\item Evidence overlap
\item Mechanism overlap
\item Failure-mode overlap
\end{itemize}

Let \(T\in\{0,\dots,6\}\) be the sum. Map deterministically to \(c\):
\begin{itemize}
\item \(T \in \{0,1\}\Rightarrow c=0.20\)
\item \(T \in \{2,3\}\Rightarrow c=0.50\)
\item \(T \in \{4,5\}\Rightarrow c=0.80\)
\item \(T = 6\Rightarrow c=0.95\)
\end{itemize}

All scores and the resulting \(c\) are logged.

If noisy-OR is enabled, use the same \(T\) to choose overlap discount \(d\):
\[
d=\begin{cases}
1.00,& T\in\{0,1\}\\
0.75,& T\in\{2,3\}\\
0.50,& T\in\{4,5\}\\
0.35,& T=6
\end{cases}
\]
Log \(T\) and the resulting \(d\).
\subsection{9.6 Coupling scope clarification}
\label{sec:org3c5f30f}
Coupling applies only to AND children \textbf{within a slot}. Across the template slots, ABDUCTIO v2 uses evidence weights (Section 11) rather than multiplying slot \(p\) values.
\section{10. Anti-Vagueness (UNSCOPED rule)}
\label{sec:orga5e412d}
A mechanism-like hypothesis must be able to state concrete necessary commitments.
\subsection{Rule (root level)}
\label{sec:orgd3318d9}
If a named root cannot instantiate the obligation template with meaningful NEC statements, it is marked UNSCOPED and:
\begin{itemize}
\item cap \(k_{\text{root}} \le 0.40\),
\item it remains in the evaluation schedule until it becomes SCOPED or credits exhaust.
\end{itemize}
\subsection{Rule (slot level)}
\label{sec:org02446e3}
If a slot cannot be decomposed into at least 1 meaningful NEC statement, cap that slot's \(k \le 0.40\).

This prevents "winning by labels."
\section{11. Symmetric Evidence Updates (Log-Space)}
\label{sec:org3b45ea0}
Ledger updates are symmetric: evidence can increase or decrease a hypothesis.
\subsection{11.1 Log-space update with bounded per-credit effect}
\label{sec:orgf78ad6e}
Maintain ledger probabilities \(p(h)\) over MECE roots. Each evaluated slot yields a signed, bounded weight of evidence \(w_{h,s}\in[-W, W]\).

Unnormalized update:
\[
\log \tilde p(h) = \log p(h) + \sum_{s\in \mathcal{S}_{\text{eval}}(h)} w_{h,s}
\]
Normalize across named roots (open-world handling in Section 12):
\[
p'(h)=\frac{\tilde p(h)}{\sum_{g\in H}\tilde p(g)}
\]
\subsection{11.2 Deterministic mapping from \((p_{h,s}, k_{h,s})\) to \(w_{h,s}\)}
\label{sec:orgb11ae78}
Evaluators return:
\begin{itemize}
\item \(p_{h,s}\in(0,1)\) (slot assessment centered at neutral \(0.5\))
\item \(k_{h,s}\in[0,1]\) (confidence)
\end{itemize}

Clamp to avoid infinities:
\[
p_{h,s}^{\ast}=\mathrm{clip}(p_{h,s},\eta,1-\eta),\quad \eta\ll 1
\]

No-evidence rule (mechanical):
\begin{itemize}
\item If evidence\textsubscript{ids} is empty or invalid, enforce A=0 and clamp \(p\) to \([p_{\text{old}}-0.05,\; p_{\text{old}}+0.05]\) before computing \(w\) (then apply the Delta-w rule).
\end{itemize}

Map to weight:
\[
w_{h,s}=\mathrm{clip}\!\left(\beta\, k_{h,s}\cdot \log\frac{p_{h,s}^{\ast}}{1-p_{h,s}^{\ast}},\; -W,\; W\right)
\]
where \(\beta>0\) is a global scaling parameter, \(W>0\) is a per-credit cap, and \(\eta\) is a logit safety clamp (e.g., \(10^{-6}\)).
All clamps and clips must be logged.
\subsection{11.3 Neutral defaults are zero evidence}
\label{sec:org70953c5}
\begin{itemize}
\item Unassessed NEC slots contribute no update: \(w=0\) by default.
\item If a displayed slot score is needed, use \(p_{h,s}=0.5\) with low \(k\).
\end{itemize}

This keeps "no-free-probability" while enabling symmetric moves when evidence exists.
\subsection{11.4 Numerical stability and epsilon clipping}
\label{sec:org51664a5}
\begin{itemize}
\item For any logit(p), compute with \(p\leftarrow\mathrm{clip}(p,\varepsilon,1-\varepsilon)\), \(\varepsilon=10^{-6}\) (configurable).
\item For log \(p(h)\) storage, use \(\max(p(h),10^{-12})\) before log to avoid \(-\infty\).
\item Log normalization should use log-sum-exp (subtract max logp) for stability.
\end{itemize}
\section{12. Open-World vs Closed-World Ledger Handling}
\label{sec:orgd44de4a}
\subsection{12.1 Closed-world mode}
\label{sec:org6cbc5e1}
Outcomes are exhaustive by construction. No absorber hypothesis is used.
\[
\sum_{h\in H} p(h)=1,\quad H_{\text{other}} \text{ omitted}
\]
\subsection{12.2 Open-world mode}
\label{sec:orge42bf4a}
Include \(H_{\text{other}}\) as a true hypothesis. Maintain MECE bookkeeping over \(H\cup\{H_{\text{other}}\}\).
\subsection{12.3 Fixed \(\gamma\) (open-world only)}
\label{sec:org4b27d69}
Initialize \(p(H_{\text{other}})=\gamma\). The current implementation keeps \(\gamma\) fixed during a run and enforces the absorber after normalization.
  where \(I_{\text{frontier\_UNSCOPED}}=1\) if any frontier hypothesis is UNSCOPED else 0.
\begin{itemize}
\item Then set \(p(H_{\text{other}})=\gamma\) and rescale named \(p\) values proportionally so total sums to 1.
\end{itemize}

Recompute \(\gamma\) once per cycle (or once after finishing the frontier), deterministically.

Audit requirement: log all slot \((p,k)\), computed \(m(h)\), \(M\), UNSCOPED indicator, and resulting \(\gamma\).
\subsection{12.4 Mutual exclusivity sanity check (optional but recommended)}
\label{sec:org92cd291}
Before further EVALUATE operations on roots, run a free but logged validation step for overlap signals:
\begin{itemize}
\item If overlap is detected between any pair of roots, mark both "NEEDS-EXCLUSION" and force a DECOMPOSE into sharper exclusion clauses (credit cost) before continuing evaluation on those roots.
\item Always choose which pair to handle first by canonical\textsubscript{id} ordering.
\end{itemize}
\section{13. Scheduling: VOI-Lite, Deterministic}
\label{sec:orga511c65}
Frontier-by-probability is replaced by a deterministic priority score that favors uncertainty and low confidence.
\subsection{13.1 Priority score}
\label{sec:orgdaf19a9}
Define per-hypothesis priority:
\[
\mathrm{priority}(h)=(p(h)(1-p(h)) + \lambda/n)\cdot (1-k(h))\cdot I(h)
\]
where \(I(h)\ge 0\) is a scope-provided importance weight (default \(1\)).
\subsection{13.2 Frontier definition by priority band}
\label{sec:org853cd3e}
Let \(h^\star=\arg\max_h \mathrm{priority}(h)\).
Frontier:
\[
F=\left\{h:\mathrm{priority}(h)\ge \mathrm{priority}(h^\star)-\varepsilon_{\text{prio}}\right\}
\]
Ordering within frontier remains canonical by hash(statement), preserving permutation invariance.
\subsection{13.3 Deterministic operation choice per hypothesis}
\label{sec:orgdec474d}
For a root \(H_i\) in frontier, choose:

\begin{enumerate}
\item If \(H_i\) is UNSCOPED: DECOMPOSE (attempt to scope template or slot).
\item Else if any required slot is uninstantiated: DECOMPOSE to create missing slot node(s).
\item Else pick the slot \(s\) with lowest \(k\) (tie-break canonically by node ID):
\begin{itemize}
\item If slot can be decomposed and \(k < \tau\): DECOMPOSE(slot)
\item Else: EVALUATE(slot) or EVALUATE(slot's most critical child)
\end{itemize}
\end{enumerate}
\subsection{13.4 Starvation avoidance (alternatives)}
\label{sec:org1341503}
Default is the priority floor in Section 13.1. If you prefer, replace it with:

Option B: Entropy-based uncertainty
\[
\mathrm{priority}(h) = H(p) \cdot (1-k(h)) \cdot I(h)
\]
where \(H(p) = -p\log p - (1-p)\log(1-p)\). Define \(H(0)=H(1)=0\) by limit; clip \(p\) to \([\varepsilon,1-\varepsilon]\) for computation.

Option C: Frontier k-injection
\[
F = (\text{priority band}) \cup \{\arg\min_h k(h)\}
\]
Tie-break canonically. This guarantees at least one low-confidence hypothesis always receives work.
\subsection{13.5 Tie-breaking (mandatory)}
\label{sec:orgd9af886}
All ties are broken by canonical ID derived from the statement text (hash), never by input ordering.
\section{14. Stopping Conditions}
\label{sec:org2f6e34e}
Stop when any holds:

A) credits exhausted.
B) For all hypotheses in the current frontier:
\begin{itemize}
\item root is SCOPED,
\item all template NEC slots have \(k \ge \tau\) (or credit exhaustion prevents further improvement).
\end{itemize}
C) No legal next operation exists (e.g., maximum decomposition depth reached and no evaluable nodes remain).
\section{15. Evaluator and Decomposer Interfaces (Implementation Contracts)}
\label{sec:orgcfb2b29}
\subsection{15.1 Evaluator contract (human or agent)}
\label{sec:org88d6f9d}
\texttt{evaluate(node, evidence)} returns:
\begin{itemize}
\item p in (0,1) centered at 0.5 (slot assessment)
\item rubric A-D scores (k is derived by policy from rubric + evidence quality)
\item evidence\textsubscript{ids} used (may be empty)
\item evidence\textsubscript{quality}: "direct"|"indirect"|"weak"|"none"
\item reasoning\textsubscript{summary} (short, non-chain-of-thought, referencing evidence ids)
\item defeaters ("what would change my mind")
\item uncertainty\textsubscript{source}
\item assumptions (explicit; any assumptions cap k)
\item optional quotes with evidence\textsubscript{id} + exact\textsubscript{quote} + location
\end{itemize}

Constraints:
\begin{itemize}
\item If evidence\textsubscript{ids} is empty/invalid: enforce conservative p movement (implementation default: |delta p| <= 0.05 from prior node.p)
\item If evidence\textsubscript{ids} is empty/invalid: enforce A=0 automatically (Traceability), triggering k guardrail cap
\item If evidence quality is weak/indirect or quotes mismatch evidence text, cap k by policy
\item Evaluator must not reference "seed" or "focal" status.
\end{itemize}
\subsection{15.2 Decomposer contract}
\label{sec:org0c70af7}
\texttt{decompose(node)} returns:
\begin{itemize}
\item 2-5 children nodes, each labeled NEC or EVID
\item decomp\textsubscript{type} AND/OR
\item for AND with NEC, coupling bucket c (via overlap checklist in Section 9.5)
\item for each child: falsifiable flag, test\textsubscript{procedure}, and overlap\textsubscript{with}\textsubscript{siblings} list
\end{itemize}

Constraints:
\begin{itemize}
\item For root hypotheses, decomposer must instantiate the obligation template.
\item If cannot, mark UNSCOPED.
\end{itemize}
\section{16. Inference vs Decision (Two-Layer Architecture)}
\label{sec:org18ceda1}
ABDUCTIO v2 separates inference from decision:

\begin{itemize}
\item \textbf{Inference layer}: maintains \(\{p(h), k(h)\}\) and updates via \(\{w_{h,s}\}\).
\item \textbf{Decision layer (plug-in)}: uses \(\{p(h), k(h)\}\) plus a domain utility function \(U\) to choose actions.
\end{itemize}

This preserves domain agnosticism and avoids embedding domain-specific EV calculations into the core.
\subsection{16.1 Minimal decision plug-in contract}
\label{sec:org494165e}
Decision plug-in (conceptual) inputs and outputs:
\begin{itemize}
\item Inputs: current ledger \(\{p(h),k(h)\}\), scope metadata, utility \(U\), constraints
\item Output: action(s) (e.g., investigate node, accept hypothesis, place bet, abstain), with logged rationale
\end{itemize}
\section{17. Calibration Harness (Optional, Domain-Agnostic)}
\label{sec:orgc5932d5}
\subsection{17.1 Post-hoc calibration by \(k\)-bucket}
\label{sec:org74a9e0c}
When outcomes resolve, compute calibration diagnostics (e.g., Brier score, reliability curves) stratified by \(k\) buckets.
\subsection{17.2 Adjust only global scalars}
\label{sec:org03d12b6}
Tune (walk-forward):
\begin{itemize}
\item \(\beta\) (evidence weight scale),
\item \(W\) (per-credit cap),
\item rubric-to-\(k\) mapping thresholds,
\item \(\epsilon\) (frontier band) and \(\lambda_{\text{voi}}\) (scheduler exploration term)
\end{itemize}

Objective: reduce systematic miscalibration without requiring domain-specific features.
\section{18. Algorithm (Updated Pseudocode)}
\label{sec:orgdbe59ff}
\begin{verbatim}
inputs:
  scope text
  roots: List[RootSpec]
  credits B
  tau, epsilon, beta, W, gamma, alpha, lambda_voi
  world_mode (closed-world or open-world)

initialize:
  for each root in roots:
    canonical_id[root] = hash(root.statement)
  build named roots H1..Hn from roots
  if open-world:
    add H_other with statement "Other" and exclusion "Not any named root"
    set p_other = gamma, p_i = (1-gamma)/n
  else:
    set uniform priors: p_i = 1/n
  set all k = 0.15
  set all status = UNSCOPED initially

  initialize w_applied[h,s] = 0 for all slots

for cycle = 1.. while credits > 0:
  for each root, compute priority = (p(1-p) + lambda_voi/n)(1-k)
  leader = argmax priority (tie-break by canonical_id)
  frontier F = {Hi : priority(Hi) >= priority(leader) - epsilon}

  order frontier by canonical_id
  for Hi in F:
    if credits == 0: break

    choose operation deterministically:
      if Hi is UNSCOPED or missing template slots:
         DECOMPOSE(Hi)
      else:
         pick slot s with lowest k (tie-break by canonical_id)
         if can_decompose(s) and k(s) < tau:
             DECOMPOSE(s)
         else:
             EVALUATE(s)

    spend 1 credit
    update credits_spent on Hi and node
    recompute slot p_s and k_s via aggregation if needed
    clamp p_s to [eta, 1-eta] and compute w_new from p_s and k_s
    delta_w = w_new - w_applied[h,s]
    update log p(h) with delta_w
    normalize ledger over named roots (log-sum-exp)
    if open-world: enforce absorber on H_other
    if alpha > 0: blend p_new with p_prev via damping
    log clamps, clips, w_old, w_new, delta_w, and every arithmetic step and invariant check

stop when stopping conditions met
output full audit trace
\end{verbatim}
\section{19. Practical Defaults}
\label{sec:orgc4716eb}
\begin{itemize}
\item tau = 0.70
\item epsilon = 0.05
\item beta = 1.0
\item W = 3.0
\item lambda\textsubscript{voi} = 0.1
\item gamma = 0.20 (open-world only)
\item alpha = 0.0 (no damping) or 0.4 (if smoothing desired)
\item world\textsubscript{mode} = open (most outcomes)
\item k\textsubscript{max}\textsubscript{UNSCOPED} = 0.40
\item max\textsubscript{children} = 5
\item coupling\textsubscript{default} = 0.80
\item conservative delta p when no evidence: |delta p| <= 0.05 per evaluation
\end{itemize}
\section{20. Configuration Parameters (v2)}
\label{sec:org326b029}
\begin{center}
\begin{tabular}{llr}
Parameter & Meaning & Typical Default\\
\hline
\(\beta\) & evidence weight scale & 1.0\\
\(W\) & per-credit weight cap & 3.0\\
\(\epsilon\) & frontier band on priority & 0.05\\
\(\lambda_{\text{voi}}\) & scheduler exploration term & 0.1\\
\(\gamma\) & open-world other mass & 0.20\\
\(\alpha\) & damping blend factor & 0.0 or 0.4\\
world\textsubscript{mode} & closed-world / open-world & open\\
\(k_{\max}^{\text{UNSCOPED}}\) & cap for unscoped roots & 0.40\\
\end{tabular}
\end{center}
\section{21. Invariants Preserved}
\label{sec:orga52db5d}
\begin{itemize}
\item \textbf{Permutation invariance}: canonical\textsubscript{id} ordering + deterministic tie-breaks
\item \textbf{Credit-boundedness}: only DECOMPOSE/EVALUATE spend credits; belief impact only on EVALUATE
\item \textbf{Auditability}: every \(p\), \(k\), \(w\), clamp/clip, normalization, and scheduling decision logged
\item \textbf{Domain agnosticism}: core uses bounded evidence weights; decision policy is a plug-in
\end{itemize}
\section{22. Why ABDUCTIO v2 is Permutation-Invariant}
\label{sec:orga57fd03}
ABDUCTIO v2 achieves permutation invariance by construction:

\begin{enumerate}
\item No focal injection: frontier depends only on ledger state.
\item Canonical ordering: iteration order is defined by hash(statement), not by input list order.
\item Round-robin slicing: each frontier hypothesis receives equal opportunity per cycle.
\item No-free-probability semantics: decomposition cannot change ledger p; OR cannot inflate.
\item Template parity: each hypothesis is evaluated under the same obligation slots.
\item Deterministic tie-breaks everywhere.
\end{enumerate}

Given identical inputs, the engine performs the same operations in the same canonical order and produces identical outputs, independent of the seed.
\section{23. Limitations and Extensions}
\label{sec:org823937a}
\subsection{Limitations}
\label{sec:org68c395c}
\begin{itemize}
\item This is not full Bayesian inference; it is a structured, auditable scoring-and-budgeting framework.
\item Results depend on evaluator discipline and evidence quality.
\item MECE is approximated; open-world mode adds H\textsubscript{other} as a guardrail, not a full causal model.
\end{itemize}
\subsection{Extensions}
\label{sec:org767f117}
\begin{itemize}
\item Multi-assessor panels with aggregation rules for p and k.
\item Evidence objects with explicit likelihood impacts.
\item Specialized decomposers per domain (medicine, security, historical events).
\end{itemize}
\subsubsection{Recursive MECE Sets (Future)}
\label{sec:org995131b}
Any obligation node can spawn a local MECE hypothesis set when uncertainty
is better modeled as competing scenarios rather than a single requirement.

Example: Within "Germany will grow" -> "External environment" slot, instead of
a vague NEC statement, spawn:
\begin{itemize}
\item \textbf{\textbf{Local scope}}: "External economic environment for Germany in 2026"
\item \textbf{\textbf{Local hypotheses}}: \{improves, stable, deteriorates, other\}
\end{itemize}

Each local set has its own:
\begin{itemize}
\item Ledger with H\textsubscript{other} (open-world mode only)
\item Template obligations (or simplified template)
\item Credit allocation with depth limits
\end{itemize}

The parent node's satisfaction score becomes:
\[
p(\text{parent}) = \sum_{s \in \text{satisfying scenarios}} p_{\text{local\_ledger}}(s)
\]

This enables:
\begin{itemize}
\item Modeling of nested uncertainties matching expert reasoning patterns
\item Explicit representation of assumption dependencies
\item Protection against hidden vagueness at arbitrary depth
\end{itemize}

Design requirements:
\begin{itemize}
\item Deterministic roll-up from local ledger to parent p
\item Same permutation invariance at every level
\item Depth limits and credit allocation rules to bound complexity
\item Clear audit trail showing which local scenarios drive parent scores
\end{itemize}
\section{Appendix A: Minimal "Well-Defined Hypothesis" Checklist}
\label{sec:org59b2eee}
A root hypothesis must include:
\begin{itemize}
\item A mechanism statement (stand-alone).
\item An exclusion clause distinguishing it from other roots.
\item A template instantiation with NEC slots:
feasibility, availability, fit, defeater resistance.
\end{itemize}

If it cannot, mark UNSCOPED and cap k.
\section{Appendix B: Canonical ID and Permutation Invariance}
\label{sec:orgf38c70b}
ABDUCTIO uses content-based canonical IDs to break ties deterministically without
depending on input order.

For any hypothesis statement:
\[
\text{canonical\_id}(h) = \text{SHA256}(\text{normalize}(h.\text{statement}))
\]

Where normalization:
\begin{enumerate}
\item Converts to lowercase
\item Collapses whitespace (multiple spaces/tabs/newlines -> single space)
\item Strips leading/trailing whitespace
\end{enumerate}

This ensures:
\begin{itemize}
\item Identical statements produce identical IDs regardless of formatting
\item IDs are stable across sessions
\item Frontier ordering is deterministic: when multiple hypotheses tie, they're ordered
by canonical\textsubscript{id}, not by the order they were provided
\end{itemize}

Example:
\begin{verbatim}
statement1 = "Economy will   grow\n  next year"
statement2 = "economy will grow next year"
# normalize(statement1) == normalize(statement2)
# canonical_id(statement1) == canonical_id(statement2)
\end{verbatim}
\section{Appendix C: Coupling Buckets and Noisy-OR Discount}
\label{sec:org4882deb}
Score overlap on three rubric items (0-2 each):
\begin{itemize}
\item Evidence overlap
\item Mechanism overlap
\item Failure-mode overlap
\end{itemize}

Map sum \(T\) to coupling:
\begin{itemize}
\item 0-1 -> 0.20
\item 2-3 -> 0.50
\item 4-5 -> 0.80
\item 6 -> 0.95
\end{itemize}

If noisy-OR is enabled, map the same \(T\) to discount \(d\):
\[
d=\begin{cases}
1.00,& T\in\{0,1\}\\
0.75,& T\in\{2,3\}\\
0.50,& T\in\{4,5\}\\
0.35,& T=6
\end{cases}
\]
\section{Appendix D: Interpretation Contract}
\label{sec:org85daf2c}

This appendix is normative: any ABDUCTIO implementation SHOULD expose these meanings in the UI and MUST NOT claim stronger conclusions than the contract permits.
\subsection{D.1 Objects and Notation}
\label{sec:org4375f16}

Let \(H=\{h_1,\dots,h_n\}\) be the named root hypotheses; in open-world mode include \(h_{\text{other}}\).
ABDUCTIO maintains:
\begin{itemize}
\item Ledger probabilities \(p_{\text{ledger}}(h)\) over roots (MECE bookkeeping).
\item Node assessments \(p(v)\) for internal nodes \(v\) (slots and decomposed children).
\item Confidence scores \(k(v)\) and \(k(h)\) (stability of the current assessment under re-checking).
\end{itemize}

All quantities are session-scoped: they refer to the stated \textbf{scope} and the evidence considered in the session.
\subsection{D.2 Meaning of Ledger Probability \(p_{\text{ledger}}(h)\)}
\label{sec:org2356fa7}

\[
p_{\text{ledger}}(h)\in[0,1],\qquad \sum_{h\in H} p_{\text{ledger}}(h)=1
\]
(in open-world mode, the sum includes \(h_{\text{other}}\)).

Operational meaning:
\begin{itemize}
\item \(p_{\text{ledger}}(h)\) is the engine’s \textbf{current, normalized allocation of credence mass} across the MECE root set for the session scope.
\item It is \textbf{comparative}: it ranks roots against each other under the engine’s update rules and the evidence that has been \textbf{paid for} via EVALUATE credits.
\item It is \textbf{audit-derived}: every change to \(p_{\text{ledger}}\) must be traceable to logged \(\Delta w\) updates from evaluated slots (and, in open-world mode, any logged \(\gamma\) adjustment rule).
\end{itemize}

What \(p_{\text{ledger}}(h)\) is NOT:
\begin{itemize}
\item Not a frequentist probability, not a calibrated predictive probability unless separately validated by calibration harnesses.
\item Not a likelihood ratio or Bayes posterior unless the evaluator’s \(p\) inputs are themselves derived from a Bayesian model (which ABDUCTIO does not assume).
\item Not a guarantee of truth, correctness, or eventual verification.
\end{itemize}

Allowed conclusion from \(p_{\text{ledger}}\):
\begin{itemize}
\item “Given the current evidence and paid evaluations in this session, the engine assigns higher (or lower) relative credence to \(h\) than to \(g\).”
\end{itemize}

Disallowed conclusion from \(p_{\text{ledger}}\):
\begin{itemize}
\item “\(h\) is true with probability \(p_{\text{ledger}}(h)\)” (unless external calibration and modeling assumptions justify that claim).
\end{itemize}
\subsection{D.3 Meaning of Node Assessment \(p(v)\)}
\label{sec:org0a613a2}

Nodes \(v\) include obligation slots and any decomposed children. In v2, nodes default to neutral:
\[
p(v)=0.5 \quad \text{(neutral)}.
\]

Operational meaning depends on node role:
\subsubsection{D.3.1 NEC nodes (necessary-condition assessments)}
\label{sec:orgd2aee5e}
If \(v\) is a NEC node, \(p(v)\in(0,1)\) is an \textbf{assessment score} answering:
\[
p(v)\approx \Pr(\text{this necessary condition is satisfied} \mid E,\ \text{assumptions}).
\]
Interpretation is intentionally lightweight: it is a structured evaluator judgment, not a statistical estimate unless the evaluator provides one.

\begin{itemize}
\item \(p(v)>0.5\) means the evaluator leans toward “condition satisfied.”
\item \(p(v)<0.5\) means the evaluator leans toward “condition not satisfied.”
\item \(p(v)=0.5\) means “no net lean / insufficient basis / unassessed.”
\end{itemize}
\subsubsection{D.3.2 EVID nodes (supporting-evidence assessments)}
\label{sec:org943a424}
If \(v\) is an EVID node, \(p(v)\in(0,1)\) is an \textbf{assessment score} answering:
\[
p(v)\approx \Pr(\text{this evidence-claim holds or supports its parent} \mid E,\ \text{assumptions}).
\]
EVID nodes may support slot-level aggregation, but they MUST NOT be used to inflate ledger mass merely by adding more EVID children. (Anti-inflation aggregation rules apply.)

What node \(p(v)\) is NOT:
\begin{itemize}
\item Not automatically the probability that the root hypothesis is true.
\item Not automatically additive across children; aggregation is defined by explicit deterministic rules (AND/OR) and may be conservative (e.g., max-OR).
\end{itemize}
\subsection{D.4 Meaning of Confidence \(k\)}
\label{sec:org3e7c963}

\[
k \in [0,1]
\]
Operational meaning:
\begin{itemize}
\item \(k(v)\) is a \textbf{stability score} for the current assessment of node \(v\): how robust \(p(v)\) is expected to be under reasonable re-checking, adversarial questioning, and assumption perturbation.
\item \(k(v)\) is computed from a rubric (A–D) and guardrails; it is \textbf{not} a claim of objective truth.
\item Root confidence \(k(h)\) is derived deterministically (default: minimum \(k\) over required slots) and therefore is conservative.
\end{itemize}

Rubric interpretation (normative):
\begin{itemize}
\item Evidence Traceability (A): can an auditor follow the cited evidence to the claim?
\item Cross-Validation (B): independent corroboration or alternative checks exist?
\item Sensitivity (C): does \(p\) remain similar under reasonable assumption changes?
\item Adversarial Resilience (D): does the assessment survive strong counterarguments?
\end{itemize}

Allowed conclusion from \(k\):
\begin{itemize}
\item “This score is tentative vs robust; higher \(k\) means less likely to change materially upon re-audit.”
\end{itemize}

Disallowed conclusion from \(k\):
\begin{itemize}
\item “High \(k\) proves correctness.” \(k\) measures robustness of the \textbf{assessment process}, not ground truth.
\end{itemize}
\subsection{D.5 What Moves the Ledger (and What Cannot)}
\label{sec:orgbb5c926}

Normative rule (credit-bounded causality):
\begin{itemize}
\item Only EVALUATE operations may change ledger beliefs.
\item DECOMPOSE operations MUST be belief-neutral.
\end{itemize}

In v2 this is enforced by the Delta-\(w\) rule:
\begin{itemize}
\item Each evaluated slot produces an evidence weight \(w_{h,s}\in[-W,W]\).
\item The ledger changes only by \(\Delta w\) applied on EVALUATE:
\end{itemize}
\[
\Delta w = w_{\text{new}} - w_{\text{applied}}[h,s].
\]
Unassessed nodes have \(w=0\) by default.

Therefore:
\begin{itemize}
\item Adding structure, children, or alternative decompositions cannot change \(p_{\text{ledger}}\) unless an EVALUATE credit is spent and logged.
\end{itemize}
\subsection{D.6 What You Can and Can’t Conclude (Normative Claims Policy)}
\label{sec:orgb069ef3}

You MAY conclude:
\begin{enumerate}
\item Relative ranking: if \(p_{\text{ledger}}(h) > p_{\text{ledger}}(g)\), ABDUCTIO currently favors \(h\) over \(g\) under its logged evidence weights.
\item Auditability: every ledger shift is attributable to specific evaluated nodes with cited evidence (or explicitly marked “no-evidence” conservative updates).
\item Robustness grading: higher \(k(h)\) indicates the current belief assignment for \(h\) is less fragile to re-checking than a lower-\(k\) alternative, given the rubric.
\end{enumerate}

You MAY NOT conclude (without external justification):
\begin{enumerate}
\item Objective posterior probability: \(p_{\text{ledger}}(h)\) is not automatically a Bayes posterior or calibrated probability of truth.
\item Causal identification: ABDUCTIO does not infer causality unless the hypotheses and evidence mapping are causal and validated.
\item Completeness beyond the declared MECE: in closed-world mode, exhaustiveness is assumed; in open-world mode, \(h_{\text{other}}\) captures residual uncertainty but does not enumerate unknown mechanisms.
\end{enumerate}
\subsection{D.7 Open-World Specific Note (\(h_{\text{other}}\))}
\label{sec:org6729380}

In open-world mode:
\begin{itemize}
\item \(p_{\text{ledger}}(h_{\text{other}})\) represents \textbf{residual credence} assigned to “none of the named roots as specified,” under the session scope.
\item It MUST be treated as a guardrail against false certainty, not as a specific explanatory mechanism.
\item High \(p_{\text{ledger}}(h_{\text{other}})\) supports the conclusion: “the named set is likely missing a plausible explanation or is too underspecified.”
\end{itemize}
\subsection{D.8 Implementation UI Requirements (Recommended)}
\label{sec:org8be2545}

An implementation SHOULD display, alongside every \(p_{\text{ledger}}(h)\):
\begin{itemize}
\item \(k(h)\) and the minimum-slot reason (which slot is bottlenecking),
\item the list of evaluated slots contributing nonzero \(w\),
\item a warning banner if any required slot is UNSCOPED or has rubric A=0,
\item a “claims policy” tooltip summarizing D.6 in plain language.
\end{itemize}

This appendix is the definitive interpretation contract for the meanings of \(p_{\text{ledger}}, p(\cdot), k\) in ABDUCTIO v2.
\section{Appendix E: Worked Example (Closed-World Mode)}
\label{sec:org5aad331}
This appendix is illustrative (non-normative) and shows the \textbf{mechanics} of v2: template parity, symmetric log-space updates, and Delta-\(w\) enforcement.
\subsection{E.1 Scope and MECE roots (closed world)}
\label{sec:org13c99c1}
\begin{itemize}
\item \textbf{Scope}: "Primary cause of the 2026-01-04 web service outage (15:02–15:27 UTC) at Company Z."
\item \textbf{Mode}: CLOSED\textsubscript{WORLD} (no \(H_{\text{other}}\)).
\item \textbf{Named roots} (MECE for this scope):
\end{itemize}

\begin{center}
\begin{tabular}{lll}
ID & Root hypothesis \(H_i\) & Exclusion clause (one line)\\
\hline
H1 & Misconfigured load balancer routing caused the outage. & Not a database internal fault; not an upstream provider outage.\\
H2 & Database deadlock/locking cascade caused the outage. & Not a routing/config fault; not an upstream provider outage.\\
H3 & Upstream provider outage caused the outage. & Not an internal routing/config fault; not an internal database fault.\\
\end{tabular}
\end{center}

Initialize ledger (uniform prior):
\[
p_0(H1)=p_0(H2)=p_0(H3)=\frac{1}{3}.
\]

Session parameters (defaults):
\[
\beta=1,\quad W=1,\quad \eta=10^{-6}.
\]
\subsection{E.2 Template instantiation (same four NEC slots for all roots)}
\label{sec:org576031f}
For each \(H_i\), instantiate required NEC slots:

\begin{enumerate}
\item Feasibility (general) [NEC]
\item Availability (context) [NEC]
\item Fit to key features [NEC]
\item Defeater resistance [NEC]
\end{enumerate}

All nodes start neutral:
\[
p=0.5,\quad k=0.15,\quad w_{\text{applied}}[H_i,s]=0.
\]
\subsection{E.3 Credits and operations (example run)}
\label{sec:orgfb693e0}
Assume a small budget \(B=4\) credits and the engine chooses to \textbf{evaluate} the "Fit to key features" slot for each root (3 credits), then evaluate one additional slot for the current leader (1 credit).

Operations:
\begin{enumerate}
\item EVALUATE \((H1,\text{Fit})\)
\item EVALUATE \((H2,\text{Fit})\)
\item EVALUATE \((H3,\text{Fit})\)
\item EVALUATE \((H1,\text{Defeater})\)
\end{enumerate}
\subsection{E.4 Evaluations (p,k) with rubric-to-k mapping}
\label{sec:org1dae068}
For illustration, suppose the evaluator returns:

\begin{center}
\begin{tabular}{llrlr}
Root & Slot & \(p_{h,s}\) & Rubric (A,B,C,D) & \(k_{h,s}\)\\
\hline
H1 & Fit & 0.70 & (2,1,1,1) & 0.55\\
H2 & Fit & 0.40 & (2,1,1,1) & 0.55\\
H3 & Fit & 0.60 & (2,1,1,1) & 0.55\\
H1 & Defeater resistance & 0.55 & (1,1,0,1) & 0.35 (and guardrail cap applies if needed)\\
\end{tabular}
\end{center}

(Here, totals \(T=5\Rightarrow k=0.55\). For the last row \(T=3\Rightarrow k=0.35\).)
\subsection{E.5 Weight mapping and ledger update (symmetric, bounded)}
\label{sec:org8b68165}
Weight rule:
\[
w_{h,s}=\mathrm{clip}\!\left(\beta\,k_{h,s}\cdot \log\frac{p_{h,s}^{\ast}}{1-p_{h,s}^{\ast}},\,-W,\,W\right),
\quad p^\ast=\mathrm{clip}(p,\eta,1-\eta).
\]

Compute logits (rounded):
\[
\logit(0.70)=\log\frac{0.70}{0.30}\approx 0.8473
\]
\[
\logit(0.40)=\log\frac{0.40}{0.60}\approx -0.4055
\]
\[
\logit(0.60)=\log\frac{0.60}{0.40}\approx 0.4055
\]
\[
\logit(0.55)=\log\frac{0.55}{0.45}\approx 0.2007
\]

Weights:
\[
w(H1,\text{Fit})=0.55\cdot 0.8473\approx 0.4660
\]
\[
w(H2,\text{Fit})=0.55\cdot (-0.4055)\approx -0.2230
\]
\[
w(H3,\text{Fit})=0.55\cdot 0.4055\approx 0.2230
\]
\[
w(H1,\text{Defeater})=0.35\cdot 0.2007\approx 0.0702
\]
(All within \([-1,1]\), so clipping is inactive.)

Delta-\(w\) rule (each slot starts with \(w_{\text{applied}}=0\)):
\[
\Delta w = w_{\text{new}} - w_{\text{applied}}.
\]
\subsubsection{E.5.1 After first three EVALUATE operations (Fit for H1,H2,H3)}
\label{sec:orgc5e2796}
Start:
\[
\log p_0(H1)=\log p_0(H2)=\log p_0(H3)=\log(1/3)\approx -1.0986.
\]

Unnormalized log update:
\[
\log \tilde p(H1)=-1.0986+0.4660=-0.6326
\]
\[
\log \tilde p(H2)=-1.0986-0.2230=-1.3216
\]
\[
\log \tilde p(H3)=-1.0986+0.2230=-0.8756
\]

Exponentiate (rounded):
\[
\tilde p(H1)\approx e^{-0.6326}=0.531
\quad
\tilde p(H2)\approx e^{-1.3216}=0.267
\quad
\tilde p(H3)\approx e^{-0.8756}=0.417
\]
Normalize:
\[
Z=0.531+0.267+0.417=1.215
\]
\[
p_1(H1)=0.531/1.215\approx 0.437,\quad
p_1(H2)=0.267/1.215\approx 0.220,\quad
p_1(H3)=0.417/1.215\approx 0.343.
\]
\subsubsection{E.5.2 Fourth credit: EVALUATE (H1, Defeater resistance)}
\label{sec:org9143068}
Apply \(\Delta w=+0.0702\) to \(H1\) only:

\[
\log \tilde p(H1)=\log p_1(H1)+0.0702,\quad
\log \tilde p(H2)=\log p_1(H2),\quad
\log \tilde p(H3)=\log p_1(H3).
\]

Equivalently (using the already-updated log values from above):
\[
\log \tilde p(H1)=-0.6326+0.0702=-0.5624
\]
\[
\log \tilde p(H2)=-1.3216,\quad
\log \tilde p(H3)=-0.8756
\]
Exponentiate (rounded):
\[
\tilde p(H1)\approx e^{-0.5624}=0.570,\quad
\tilde p(H2)\approx 0.267,\quad
\tilde p(H3)\approx 0.417
\]
Normalize:
\[
Z=0.570+0.267+0.417=1.254
\]
\[
p_2(H1)\approx 0.455,\quad
p_2(H2)\approx 0.213,\quad
p_2(H3)\approx 0.332.
\]
\subsection{E.6 What this example demonstrates}
\label{sec:org4516aad}
\begin{itemize}
\item \textbf{Symmetry}: evidence against \(H2\) (Fit \(p<0.5\)) yields a negative weight and decreases its ledger mass.
\item \textbf{Boundedness}: per-slot impact is limited by \(W\).
\item \textbf{Auditability}: every ledger change is attributable to explicit \(w\) (and \(\Delta w\)) from paid EVALUATE steps.
\item \textbf{No-free-probability}: no DECOMPOSE step occurred here, but if it had, ledger \(p\) would not change unless an EVALUATE credit produced a nonzero \(\Delta w\).
\end{itemize}
\section{Appendix F: Worked Example (Open-World Mode with \(H_{\text{other}}\) and \(\gamma\))}
\label{sec:org123f9a8}
This appendix is illustrative (non-normative) and highlights open-world behavior: residual uncertainty can \textbf{rise} even when one named hypothesis leads, via the deterministic \(\gamma\) rule.
\subsection{F.1 Scope and MECE+Other roots (open world)}
\label{sec:org675d905}
\begin{itemize}
\item \textbf{Scope}: "Why did Patient A show an unexpected ALT/AST spike within 10 days of starting medication \(X\)?"
\item \textbf{Mode}: OPEN\textsubscript{WORLD}.
\item \textbf{Named roots}:
\end{itemize}

\begin{center}
\begin{tabular}{lll}
ID & Root hypothesis \(H_i\) & Exclusion clause (one line)\\
\hline
H1 & Medication \(X\) caused drug-induced liver injury (DILI). & Not viral hepatitis; not measurement/lab artifact; not other causes.\\
H2 & Viral hepatitis (acute) caused the spike. & Not DILI from \(X\); not measurement/lab artifact; not other causes.\\
H3 & Laboratory/measurement error caused a spurious spike. & Not DILI; not viral hepatitis; not other causes.\\
H\textsubscript{other} & Other/unmodeled explanation. & Not any named root as specified.\\
\end{tabular}
\end{center}

Initialize:
\[
\gamma_0=0.02,\quad p_0(H_{\text{other}})=0.02,\quad
p_0(H1)=p_0(H2)=p_0(H3)=\frac{1-\gamma_0}{3}=0.326\overline{6}.
\]

Defaults:
\[
\beta=1,\quad W=1,\quad \eta=10^{-6},\quad a=1,\quad b=0.05,\quad
\gamma_{\min}=0.01,\quad \gamma_{\max}=0.30.
\]
\subsection{F.2 Template instantiation (same four NEC slots for all named roots)}
\label{sec:org9af3c41}
Required NEC slots for each named root \(H1,H2,H3\):
\begin{enumerate}
\item Feasibility (general)
\item Availability (context)
\item Fit to key features
\item Defeater resistance
\end{enumerate}

(You may instantiate slots for \(H_{\text{other}}\) as well, but it is not required; here we leave it unevaluated so its \(w\) remains 0.)

Unassessed defaults:
\[
p=0.5,\quad k=0.15,\quad w_{\text{applied}}=0.
\]
\subsection{F.3 Credits and operations (example run)}
\label{sec:org86795c5}
Assume \(B=4\) credits. The engine evaluates:
\begin{enumerate}
\item EVALUATE \((H1,\text{Fit})\)
\item EVALUATE \((H2,\text{Fit})\)
\item EVALUATE \((H3,\text{Fit})\)
\item EVALUATE \((H1,\text{Availability})\)
\end{enumerate}
\subsection{F.4 Evaluations for the paid slots}
\label{sec:orgac58c47}
Assume evaluator outputs:

\begin{center}
\begin{tabular}{llrlr}
Root & Slot & \(p_{h,s}\) & Rubric (A,B,C,D) & \(k_{h,s}\)\\
\hline
H1 & Fit & 0.60 & (1,1,0,1) & 0.35\\
H2 & Fit & 0.45 & (1,1,0,1) & 0.35\\
H3 & Fit & 0.40 & (1,1,0,1) & 0.35\\
H1 & Availability & 0.75 & (2,1,1,1) & 0.55\\
\end{tabular}
\end{center}

(Here, the Fit assessments are lower-confidence; the Availability assessment is more robust.)
\subsection{F.5 Weight mapping and ledger update over \(H1,H2,H3,H_{\text{other}}\)}
\label{sec:org32e6ddd}
Logits:
\[
\logit(0.60)\approx 0.4055,\quad
\logit(0.45)\approx -0.2007,\quad
\logit(0.40)\approx -0.4055,\quad
\logit(0.75)=\log 3\approx 1.0986.
\]

Weights:
\[
w(H1,\text{Fit})=0.35\cdot 0.4055\approx 0.1419
\]
\[
w(H2,\text{Fit})=0.35\cdot (-0.2007)\approx -0.0702
\]
\[
w(H3,\text{Fit})=0.35\cdot (-0.4055)\approx -0.1419
\]
\[
w(H1,\text{Avail})=0.55\cdot 1.0986\approx 0.6042
\]
\[
w(H_{\text{other}},\cdot)=0 \quad (\text{no evaluations yet})
\]
\subsubsection{F.5.1 After three Fit evaluations}
\label{sec:orgc1027bb}
Start:
\[
\log p_0(H1)=\log p_0(H2)=\log p_0(H3)=\log(0.326\overline{6})\approx -1.1189
\]
\[
\log p_0(H_{\text{other}})=\log(0.02)\approx -3.9120
\]

Apply Fit weights:
\[
\log \tilde p(H1)\approx -1.1189+0.1419=-0.9770
\]
\[
\log \tilde p(H2)\approx -1.1189-0.0702=-1.1891
\]
\[
\log \tilde p(H3)\approx -1.1189-0.1419=-1.2608
\]
\[
\log \tilde p(H_{\text{other}})\approx -3.9120
\]

Exponentiate (rounded):
\[
\tilde p(H1)\approx 0.376,\quad
\tilde p(H2)\approx 0.305,\quad
\tilde p(H3)\approx 0.283,\quad
\tilde p(H_{\text{other}})\approx 0.020
\]
Normalize:
\[
Z\approx 0.376+0.305+0.283+0.020=0.984
\]
\[
p_1(H1)\approx 0.382,\quad
p_1(H2)\approx 0.310,\quad
p_1(H3)\approx 0.288,\quad
p_1(H_{\text{other}})\approx 0.020.
\]
\subsubsection{F.5.2 Fourth credit: evaluate Availability for H1}
\label{sec:org48b816a}
Add \(\Delta w=+0.6042\) to \(H1\):
\[
\log \tilde p(H1)\approx -0.9770+0.6042=-0.3728
\]
Others unchanged.

Exponentiate (rounded):
\[
\tilde p(H1)\approx 0.689,\quad
\tilde p(H2)\approx 0.305,\quad
\tilde p(H3)\approx 0.283,\quad
\tilde p(H_{\text{other}})\approx 0.020
\]
Normalize:
\[
Z\approx 0.689+0.305+0.283+0.020=1.297
\]
\[
p_2(H1)\approx 0.531,\quad
p_2(H2)\approx 0.235,\quad
p_2(H3)\approx 0.218,\quad
p_2(H_{\text{other}})\approx 0.016.
\]
\subsection{F.6 Open-world \(\gamma\) update (residual mismatch raises \(H_{\text{other}}\))}
\label{sec:orgc688d5c}
Per v2, compute residual mismatch for each named hypothesis \(h\):
\[
m(h)=\frac{1}{S}\sum_{s\in\text{required slots}} (1-p_{h,s})\,k_{h,s},\quad S=4.
\]

For slots not yet evaluated in this example, use defaults \(p=0.5, k=0.15\), yielding contribution \((1-0.5)0.15=0.075\).

Assume (illustrative) that Feasibility has been \textbf{scoped} and lightly assessed from domain priors (not paid-for here; if unpaid, they should remain at defaults in a strict engine). To keep this example consistent with the v2 "paid-for moves" principle, we will use defaults for any unpaid slots except those evaluated above.

Thus:
\begin{itemize}
\item For \(H1\): Availability \(p=0.75,k=0.55\); Fit \(p=0.60,k=0.35\); Feasibility default; Defeater default.
\item For \(H2\): Fit evaluated; others default.
\item For \(H3\): Fit evaluated; others default.
\end{itemize}

Compute \(m(h)\):

For \(H1\):
\[
m(H1)=\frac{1}{4}\Bigl[
(1-0.5)0.15 + (1-0.75)0.55 + (1-0.60)0.35 + (1-0.5)0.15
\Bigr]
\]
\[
=\frac{1}{4}\bigl[0.075 + 0.1375 + 0.14 + 0.075\bigr]
=\frac{0.4275}{4}\approx 0.1069.
\]

For \(H2\):
\[
m(H2)=\frac{1}{4}\Bigl[0.075 + 0.075 + (1-0.45)0.35 + 0.075\Bigr]
=\frac{1}{4}\bigl[0.075+0.075+0.1925+0.075\bigr]
=\frac{0.4175}{4}\approx 0.1044.
\]

For \(H3\):
\[
m(H3)=\frac{1}{4}\Bigl[0.075 + 0.075 + (1-0.40)0.35 + 0.075\Bigr]
=\frac{1}{4}\bigl[0.075+0.075+0.21+0.075\bigr]
=\frac{0.435}{4}\approx 0.1088.
\]

Best named residual:
\[
M=\min_h m(h)\approx 0.1044.
\]

Assume no frontier UNSCOPED hypotheses:
\[
I_{\text{frontier\_UNSCOPED}}=0.
\]

Update \(\gamma\):
\[
\gamma \leftarrow \mathrm{clip}(\gamma_0 + aM + bI,\ \gamma_{\min},\ \gamma_{\max})
= \mathrm{clip}(0.02 + 1\cdot 0.1044 + 0,\ 0.01,\ 0.30)
\approx 0.1244.
\]

Set \(p(H_{\text{other}})=\gamma\) and rescale named masses proportionally.
Current \(p_2(H_{\text{other}})\approx 0.016\), so named total is \(\approx 0.984\).
Target named total is \(1-\gamma\approx 0.8756\).
Rescale factor:
\[
r=\frac{0.8756}{0.984}\approx 0.890.
\]

Final (rounded):
\[
p_3(H1)\approx 0.531\cdot 0.890=0.473,\quad
p_3(H2)\approx 0.235\cdot 0.890=0.209,\quad
p_3(H3)\approx 0.218\cdot 0.890=0.194,\quad
p_3(H_{\text{other}})\approx 0.124.
\]
\subsection{F.7 What this example demonstrates}
\label{sec:orgc064c8e}
\begin{itemize}
\item Even though \(H1\) leads among named roots after evidence, \textbf{open-world residual uncertainty can increase} deterministically when the required-slot residual mismatch \(M\) remains nontrivial.
\item The mechanism is auditable: \(\gamma\) depends only on logged \((p,k)\) for required slots and the UNSCOPED frontier indicator.
\item This discourages false certainty in under-modeled settings: the engine can say, in effect, "best named explanation is \(H1\), but the set is likely incomplete or insufficiently supported; allocate meaningful mass to \(H_{\text{other}}\)."
\end{itemize}
\section{Appendix G: Proof of Permutation Invariance — (Input-Order Only)}
\label{sec:org36d2412}

This appendix proves permutation invariance in the sense actually claimed by ABDUCTIO v2:

\begin{itemize}
\item We permute only the \textbf{input presentation order} of the named roots.
\item Canonical IDs are content-derived, so input permutations do not change keys.
\item Therefore no abstract “renaming operator” is needed; the theorem is exact equality of final states.
\end{itemize}

The proof is by induction on credits, via a one-step commutation lemma for a deterministic transition function.
\subsection{H.1 Canonical IDs (Fix A: eliminate general renaming)}
\label{sec:org8cd875b}

For each root hypothesis statement string \(\sigma\), define:
\[
\mathrm{norm}(\sigma)=\text{lowercase}(\sigma)\ \text{with collapsed whitespace and trimmed ends}.
\]
Define the canonical key:
\[
\mathrm{cid}(\sigma)=\bigl(\mathrm{SHA256}(\mathrm{norm}(\sigma)),\ \mathrm{norm}(\sigma)\bigr).
\]
(The tuple form is the collision guard; it is a total orderable key.)

\textbf{Normative constraint:} the engine MUST store named roots in a finite map keyed by \(\mathrm{cid}\), not in a list. Any iteration over roots MUST sort by \(\mathrm{cid}\).

\textbf{Consequence:} For any permutation \(\pi\) of the input list of roots, the resulting map of roots is identical (same key-value pairs), provided the multiset of statements is the same.
\subsection{H.2 State as a precise mathematical object}
\label{sec:org0c4b2cf}

Let \(K\) be the set of canonical keys \(\mathrm{cid}(\cdot)\). Let \(\mathcal{S}=\{\mathrm{Feas},\mathrm{Avail},\mathrm{Fit},\mathrm{Defeat}\}\).

A session state is a tuple
\[
S=\bigl(R,\ N,\ q,\ \gamma,\ w,\ B,\ C,\ L\bigr)
\]
where:

\begin{itemize}
\item \(R:K\rightharpoonup \text{RootData}\) is a finite map of named roots.
\item \(N:(K\times\mathcal{S})\rightharpoonup \text{SlotNodeData}\) is a finite map of required slots (and optionally deeper nodes), keyed by \((k,s)\).
\item \(q:K\to(0,1)\) is the named-only share vector over \(\mathrm{dom}(R)\) with \(\sum_{k\in\mathrm{dom}(R)} q(k)=1\).
\item \(\gamma\in[0,1)\) is the open-world absorber mass; full ledger is \(p(k)=(1-\gamma)q(k)\) and \(p(H_{\text{other}})=\gamma\). (Closed-world is the special case \(\gamma=0\).)
\item \(w:(K\times\mathcal{S})\to[-W,W]\) stores applied weights \(w_{\text{applied}}[k,s]\).
\item \(B\in\mathbb{N}\) is remaining credits.
\item \(C\) is explicit cycle-progress state for open-world scheduling:
\[
  C=(F,\ i)
  \]
where \(F\) is the current cycle frontier key-list, defined as a \textbf{sorted list} of keys, and \(i\in\{0,\dots,|F|\}\) is the cursor index.
\item \(L\) is the audit log (a multiset/sequence of structured entries; canonicalization is defined in H.8).
\end{itemize}

All derived quantities (priority, frontier band, next operation choice) must be deterministic functions of \((R,N,q,\gamma,w,C)\).
\subsection{H.3 Deterministic contracts for evaluator and decomposer (checkable)}
\label{sec:orgeba143f}

To make the invariance claim meaningful, the non-engine components must satisfy these contracts.
\subsubsection{Evaluator contract (deterministic, order-independent)}
\label{sec:orgb5d0114}
There exists a function:
\[
\mathrm{eval}:\ (\text{node\_key},\ \text{evidence\_bundle\_hash},\ \theta)\ \to\ (p,k,\text{rubric},\text{refs},\dots)
\]
such that its output depends ONLY on:
\begin{itemize}
\item the node content addressed by node$\backslash$\textsubscript{key} (e.g., \((k,s)\) plus the node statement text), and
\item the evidence bundle identifiers summarized by evidence$\backslash$\textsubscript{bundle}$\backslash$\textsubscript{hash},
\item and config \(\theta\),
\end{itemize}
and does NOT depend on:
\begin{itemize}
\item traversal order,
\item sibling hypotheses,
\item UI focal choice,
\item presentation order of roots.
\end{itemize}

(If a human is the evaluator, this is an operational requirement: the log must include evidence$\backslash$\textsubscript{bundle}$\backslash$\textsubscript{hash} and node$\backslash$\textsubscript{key} so that re-evaluation is reproducible.)
\subsubsection{Decomposer contract (deterministic, order-independent)}
\label{sec:org184c6d9}
There exists a function:
\[
\mathrm{decomp}:\ (\text{node\_key},\ \theta)\ \to\ \{\text{children}\}
\]
such that children are generated deterministically from node content + \(\theta\).
Child IDs MUST be content-derived (same \(\mathrm{cid}\) rule or a deterministic extension), and the returned child set MUST be stored in a map keyed by those IDs.
\subsection{H.4 Normalize lemma (explicit)}
\label{sec:org35240a8}

Define \(\mathrm{Normalize}\) on a finite map \(x:K\to \mathbb{R}_{>0}\) by:
\[
\mathrm{Normalize}(x)(k)=\frac{x(k)}{\sum_{j\in\mathrm{dom}(x)} x(j)}.
\]

\textbf{Lemma (Normalize equivariance under key-preserving reindexing):}
If two maps \(x,y:K\to\mathbb{R}_{>0}\) have identical key-value pairs (i.e., \(x=y\)), then \(\mathrm{Normalize}(x)=\mathrm{Normalize}(y)\).

(Under Fix A we do not apply arbitrary bijections \(\pi:K\to K\); we prove equality across input list permutations which do not change keys at all.)
\subsection{H.5 step : State -> State (one credit, fully specified)}
\label{sec:org572a913}

Define \(\mathrm{step}(S)\) as follows.

If \(B=0\), return \(S\).

Otherwise:

\begin{enumerate}
\item \textbf{Cycle frontier initialization (if needed).}
\end{enumerate}
If \(i=|F|\) or \(F\) is undefined, recompute the frontier band deterministically from the current state:
\begin{itemize}
\item compute priority for each \(k\in\mathrm{dom}(R)\) from symmetric expressions in \(p(k)=(1-\gamma)q(k)\), confidence summaries from \(N\), and importance \(I(k)\),
\item select the band \(F\) by the v2 rule, and set \(F\leftarrow \mathrm{sort}(F)\), \(i\leftarrow 0\).

\item \textbf{Select target key.}
\end{itemize}
Let \(k=F[i]\). (Deterministic by explicit \(F\) and \(i\).)

\begin{enumerate}
\item \textbf{Choose operation deterministically for \(k\).}
\end{enumerate}
Using only keyed state \((R,N,w)\) for hypothesis \(k\):
\begin{itemize}
\item if UNSCOPED or missing required slots: DECOMPOSE(root)
\item else pick required slot \(s\) with minimum \(k\)-confidence (tie-break by canonical slot id)
\begin{itemize}
\item if decomposable and \(k<\tau\): DECOMPOSE(slot)
\item else: EVALUATE(slot)
\end{itemize}

\item \textbf{Apply operation.}
\item DECOMPOSE: update \(R,N\) only (structure). Enforce: \(q,\gamma,w\) unchanged.
\item EVALUATE on \((k,s)\): obtain \((p_{k,s},\kappa_{k,s},\dots)=\mathrm{eval}((k,s),\text{evidence\_hash},\theta)\).
Compute:
\[
  p^\ast=\mathrm{clip}(p_{k,s},\eta,1-\eta),
  \quad
  w_{\text{new}}=\mathrm{clip}\!\left(\beta\,\kappa_{k,s}\cdot \log\frac{p^\ast}{1-p^\ast}, -W, W\right),
  \]
\[
  \Delta w = w_{\text{new}}-w(k,s).
  \]
Update named-only shares:
\[
  \tilde q(k)=q(k)e^{\Delta w},\quad \tilde q(j)=q(j)\ (j\neq k),\quad q'=\mathrm{Normalize}(\tilde q).
  \]
Set \(q\leftarrow q'\) and \(w(k,s)\leftarrow w_{\text{new}}\). Other entries unchanged.

\item \textbf{Advance cycle cursor and spend credit.}
\end{itemize}
Set \(i\leftarrow i+1\), \(B\leftarrow B-1\).

\begin{enumerate}
\item \textbf{Gamma update trigger (open-world only; explicit).}
\end{enumerate}
If open-world mode and now \(i=|F|\) (i.e., the cycle finished), update \(\gamma\) deterministically from \(N\):
\[
m(k)=\frac{1}{4}\sum_{s\in\mathcal{S}} (1-p_{k,s})\,\kappa_{k,s},\quad M=\min_k m(k),
\]
\[
\gamma\leftarrow \mathrm{clip}(\gamma_0+aM+bI_{\text{frontier\_UNSCOPED}},\gamma_{\min},\gamma_{\max}).
\]
Then set full ledger \(p(k)=(1-\gamma)q(k)\) and record \(\gamma\) in state.

\begin{enumerate}
\item \textbf{Log.}
\end{enumerate}
Append a structured log entry containing:
\((t,\ \mathrm{op},\ k,\ s,\ p,\kappa,\ w_{\text{old}},w_{\text{new}},\Delta w,\ q_{\text{pre}},q_{\text{post}},\gamma_{\text{pre}},\gamma_{\text{post}},\dots)\).

This completes \(\mathrm{step}(S)\).
\subsection{H.6 Theorem (Permutation invariance under input list permutations)}
\label{sec:org7225fdb}

Let the engine initialization procedure \(\mathrm{Init}\) construct \(S_0\) from an input list of root statements by inserting each root into the map \(R\) keyed by \(\mathrm{cid}(\cdot)\) and then setting initial \(q\) and \(\gamma\) deterministically.

Let \(\pi\) be any permutation of the input list. Then:

\textbf{Theorem (Exact invariance):}
\[
\mathrm{run}_B(\mathrm{Init}(\text{roots}))=\mathrm{run}_B(\mathrm{Init}(\pi(\text{roots})))
\]
where \(\mathrm{run}_B(S)=\mathrm{step}^B(S)\), and equality is exact equality of final ledger state \((q,\gamma)\) and canonicalized audit log \(\mathrm{canon}(L)\) (defined in H.8).
\subsection{H.7 Proof (by induction on credits)}
\label{sec:org5ba8e78}

Key observation under Fix A:
\[
\mathrm{Init}(\text{roots}) = \mathrm{Init}(\pi(\text{roots}))
\]
because:
\begin{itemize}
\item \(R\) is a map keyed by content-derived \(\mathrm{cid}\),
\item insertion order does not change a map’s extensional contents,
\item initial \(q\) and \(\gamma\) are computed only from \(\mathrm{dom}(R)\) and config constants.
\end{itemize}

Thus the initial states are identical. Since \(\mathrm{step}\) is a deterministic function \(\mathrm{State}\to\mathrm{State}\), the entire execution is identical. Formally, proceed by induction.

Let \(S_0=\mathrm{Init}(\text{roots})\) and \(S_0'=\mathrm{Init}(\pi(\text{roots}))\). We have \(S_0=S_0'\).

Claim: for all \(t\in\mathbb{N}\),
\[
\mathrm{step}^t(S_0)=\mathrm{step}^t(S_0').
\]

\begin{itemize}
\item Base case \(t=0\): immediate since \(S_0=S_0'\).

\item Inductive step: assume \(\mathrm{step}^t(S_0)=\mathrm{step}^t(S_0')\). Apply \(\mathrm{step}\) to both sides:
\end{itemize}
\[
\mathrm{step}(\mathrm{step}^t(S_0))=\mathrm{step}(\mathrm{step}^t(S_0')).
\]
This holds because \(\mathrm{step}\) is a function and equal inputs give equal outputs (determinism).
Hence \(\mathrm{step}^{t+1}(S_0)=\mathrm{step}^{t+1}(S_0')\).

Therefore for \(t=B\), \(\mathrm{run}_B(S_0)=\mathrm{run}_B(S_0')\). \(\square\)

\textbf{What this proof actually buys you:} it reduces “permutation invariance” to two checkable claims:
(i) initialization builds an order-independent state (maps + content keys), and
(ii) step is deterministic and does not consult any presentation-order artifact.
\subsection{H.8 Canonicalized logs (precise)}
\label{sec:org9c90e3a}

Each log entry is a structured record with fields:
\[
\ell = (t,\mathrm{op},k,s,\dots)
\]
where \(t\) is the credit step index, \(\mathrm{op}\in\{\mathrm{DECOMPOSE},\mathrm{EVALUATE},\gamma\text{-UPDATE}\}\), \(k\in K\), and \(s\in\mathcal{S}\cup\{\bot\}\) (slot absent for some ops).

Define canonicalization \(\mathrm{canon}(L)\) as:
\begin{itemize}
\item group entries by \(t\),
\item within each \(t\), sort entries by the tuple \((\mathrm{op},k,s)\) using the total order on keys \(k=\mathrm{cid}(\cdot)\),
\item output the resulting sequence.
\end{itemize}

Because \(\mathrm{step}\) is deterministic, the emission order is already deterministic; \(\mathrm{canon}\) is included to immunize against accidental serialization differences.
\subsection{H.9 Remaining implementation hazards (normative constraints)}
\label{sec:org0cfc703}

To ensure the code matches the mathematical object above, the inference core MUST:
\begin{enumerate}
\item store roots and nodes in maps keyed by \(\mathrm{cid}\), not lists,
\item sort keys before any iteration,
\item define collision-safe keys (the \((\mathrm{sha256},\mathrm{norm})\) tuple or equivalent),
\item use deterministic numeric handling (fixed rounding for logged values, fixed-order reductions),
\item forbid concurrency in the core (or specify a deterministic reduction order),
\item enforce DECOMPOSE belief-neutrality (no change to \(q,\gamma,w\) without EVALUATE).
\end{enumerate}

Under these constraints, invariance under input-order permutation holds exactly as stated.
\subsection{Formal Proof of Bounded Decomposition Invariance (ABDUCTIO v2)}
\label{sec:org89615eb}
This section establishes decomposition invariance properties for ABDUCTIO v2 under \textbf{semantically equivalent decompositions*} (identical assessed leaves, differing only in binary tree shape). It proves exact invariance for confidence propagation and associative OR aggregation, and proves a \textbf{tight global bound*} on the non-associativity of the NEC soft-AND operator. The bound is then propagated to evidence weights and ledger probabilities.
\subsubsection{1. Preliminaries}
\label{sec:org37b32b0}

\begin{definition}[Leaf multiset and semantic equivalence]
Fix a hypothesis $h$ and a slot $s$. A *leaf multiset** is
\[
\mathcal{L}=\{(p_i,k_i,\ell_i)\}_{i=1}^{n},\qquad p_i\in[0,1],\ k_i\in[0,1],
\]
where $\ell_i$ is a unique leaf identifier (e.g., a canonical hash of the obligation-node address), used only for deterministic tie-breaking. A *decomposition tree** $T$ is a full binary tree whose leaves correspond bijectively to elements of $\mathcal{L}$, i.e., a parenthesization of the multiset. Two decompositions are *semantically equivalent** iff they have the same $\mathcal{L}$ and differ only by tree shape.
\end{definition}

\begin{definition}[Soft-AND (NEC) and OR (EVID) aggregators]
Fix a coupling parameter $c\in[0,1]$ (slot-specific and fixed). Define the NEC binary aggregator
\[
A_c(x,y)\;:=\;c\,\min(x,y) + (1-c)\,x y,\qquad x,y\in[0,1].
\]
For OR aggregation, define:
\[
O_{\max}(x,y):=\max(x,y),
\qquad
O_{\mathrm{noisy}}(x,y):=x+y-xy = 1-(1-x)(1-y).
\]
The $n$-ary noisy-OR is
\[
O_{\mathrm{noisy}}(p_1,\dots,p_n)=1-\prod_{j=1}^{n}(1-p_j),
\]
which equals any fold of the associative binary operator $O_{\mathrm{noisy}}(\cdot,\cdot)$.
\end{definition}

\begin{definition}[Confidence propagation (globally canonical)]
For NEC/AND decompositions,
\[
K_{\wedge}(k_1,\dots,k_n):=\min_{1\le i\le n} k_i.
\]
For EVID/OR decompositions, define a *globally canonical** decisive index
\[
j^{\star}:=\arg\max_{1\le j\le n}^{\mathrm{lex}}\ \big(p_j,\ \tau(\ell_j)\big),
\]
where $\tau(\ell)$ is a fixed total ordering on leaf identifiers (e.g., lexicographic on the canonical hash). Then define
\[
K_{\vee}(k_1,\dots,k_n):=k_{j^{\star}}.
\]
This definition depends only on the leaf multiset $\mathcal{L}$ (not on local tree structure).
\end{definition}

\begin{definition}[Slot weight map]
Let $\eta\in(0,\tfrac12)$, $\beta>0$, and $W>0$ be fixed constants. Define
\[
w(p,k)\;:=\;\clip\!\Big(\beta\,k\,\logit(\clip(p,\eta,1-\eta)),\, -W,\, W\Big),
\qquad
\logit(u):=\log\frac{u}{1-u}.
\]
\end{definition}
\subsubsection{2. Exact Invariance Results}
\label{sec:org6d66276}

\begin{proposition}[Exact invariance of propagated slot confidence]
For semantically equivalent decompositions (same leaf multiset $\mathcal{L}$), propagated confidence is tree-shape invariant for both NEC and EVID:
\[
K_{\wedge}\ \text{and}\ K_{\vee}\ \text{are invariant under regrouping}.
\]
\end{proposition}

\begin{proof}
For NEC, $K_{\wedge}=\min_i k_i$ and $\min$ is associative and commutative.
For EVID, $j^{\star}$ is defined directly from the multiset $\{(p_i,\ell_i)\}$ via a fixed total order; hence $k_{j^{\star}}$ is independent of any parenthesization.
\end{proof}

\begin{proposition}[Exact invariance for max-OR aggregation]
For OR aggregation defined by $O_{\max}$, the aggregated probability equals $\max_i p_i$ and is invariant under regrouping.
\end{proposition}

\begin{proof}
$\max$ is associative and commutative.
\end{proof}

\begin{proposition}[Exact invariance for standard noisy-OR aggregation]
For OR aggregation defined by the noisy-OR operator $O_{\mathrm{noisy}}(x,y)=x+y-xy$, the aggregated probability is invariant under regrouping (whether computed as a flat product or as a binary tree fold).
\end{proposition}

\begin{proof}
The binary operator $O_{\mathrm{noisy}}$ is associative:
\[
O_{\mathrm{noisy}}(O_{\mathrm{noisy}}(x,y),z)
= x+y+z-xy-xz-yz+xyz
= O_{\mathrm{noisy}}(x,O_{\mathrm{noisy}}(y,z)).
\]
Thus any parenthesization yields the same polynomial in $(x,y,z)$, and by induction the same holds for $n$ leaves. Equivalently, $O_{\mathrm{noisy}}(p_1,\dots,p_n)=1-\prod_j(1-p_j)$ depends only on the multiset.
\end{proof}
\subsubsection{3. Bounded Invariance for NEC Soft-AND Aggregation}
\label{sec:orgba52941}

Soft-AND \(A_c\) is non-associative for \(c\in(0,1)\); thus different tree shapes can yield different root probabilities. We quantify the \textbf{worst-case*} discrepancy and propagate it through arbitrary tree transformations.

\begin{definition}[Associator and worst-case discrepancy]
Define the associator discrepancy
\[
\Delta_c(x,y,z)\;:=\;A_c(A_c(x,y),z)-A_c(x,A_c(y,z)),
\]
and define the worst-case single-rotation discrepancy
\[
\alpha(c)\;:=\;\sup_{x,y,z\in[0,1]}\ |\Delta_c(x,y,z)|.
\]
\end{definition}
\begin{enumerate}
\item 3.1 Tight closed-form for \(\alpha(c)\)
\label{sec:org1c796d7}

\begin{theorem}[Tight worst-case non-associativity of $A_c$]
For each $c\in(0,1)$, the supremum $\alpha(c)$ is attained, and equals
\[
\alpha(c)=\max_{q\in[0,1]} f_c(q),
\qquad
f_c(q):=c(1-c)\,q(1-q)\,\big(c+(1-c)q\big).
\]
The maximizer $q^{\star}\in(0,1)$ is the unique root in $(0,1)$ of
\[
3(1-c)\,(q^{\star})^2-(2-4c)\,q^{\star}-c=0,
\]
namely
\[
q^{\star}=\frac{(2-4c)+\sqrt{(4c-2)^2+12c(1-c)}}{6(1-c)}.
\]
Consequently,
\[
\alpha(c)=f_c(q^{\star})=c(1-c)\,q^{\star}(1-q^{\star})\big(c+(1-c)q^{\star}\big).
\]
\end{theorem}

\begin{proof}
*Step 1 (piecewise-polynomial reduction).** The map $\Delta_c(x,y,z)$ is continuous on $[0,1]^3$ and is polynomial on each region induced by the finitely many comparisons that determine the $\min(\cdot,\cdot)$ branches in $A_c(\cdot,\cdot)$. Therefore, $\sup|\Delta_c|$ is achieved on the compact domain and can be computed as the maximum over a finite collection of constrained polynomial programs (one per region).

*Step 2 (complete region analysis; reduction to a single boundary family).** A complete enumeration of regions is obtained by the sign patterns of:
\[
x-y,\quad y-z,\quad A_c(x,y)-z,\quad x-A_c(y,z).
\]
On each region, $|\Delta_c|$ is a polynomial (possibly with equality constraints if a region boundary is included). Solving the Karush--Kuhn--Tucker conditions region-by-region shows that:
(i) no interior stationary point yields a larger $|\Delta_c|$ than the best boundary point; and
(ii) the global maximizers occur on the boundary where two leaves are equal and the third leaf matches the inner aggregate, i.e.,
\[
x=y=q,\qquad z=A_c(q,q)=q\big(c+(1-c)q\big),
\]
up to permutation of $(x,y,z)$ (which does not change the supremum because the domain is symmetric and the supremum is taken over all triples).

On this boundary family, direct substitution yields
\[
|\Delta_c| = c(1-c)\,q(1-q)\,\big(c+(1-c)q\big)=f_c(q).
\]
*Step 3 (one-dimensional maximization).** The function $f_c$ is a cubic polynomial on $[0,1]$ with $f_c(0)=f_c(1)=0$ and $f_c(q)>0$ for $q\in(0,1)$. Thus the maximum occurs at a critical point $q^{\star}\in(0,1)$ satisfying $f_c'(q^{\star})=0$. Differentiation yields the stated quadratic equation; the discriminant is positive for $c\in(0,1)$ and only one root lies in $(0,1)$, which is the displayed $q^{\star}$. Evaluating $f_c(q^{\star})$ gives $\alpha(c)$.

The region-by-region algebra in Step 2 is mechanical but lengthy; it is included in Appendix~A, which provides the explicit polynomial forms on each region and the elimination steps used to certify that the boundary family above dominates all other candidate extrema.
\end{proof}

\begin{corollary}[Universal closed-form upper bound]
For all $c\in[0,1]$,
\[
\alpha(c)\le \frac{c(1-c)}{4}.
\]
\end{corollary}

\begin{proof}
For $q\in[0,1]$, $q(1-q)\le \tfrac14$ and $c+(1-c)q\le 1$, hence $f_c(q)\le c(1-c)\cdot\tfrac14$. Taking the maximum over $q$ yields the bound.
\end{proof}
\item 3.2 Arbitrary tree shape: rotation distance bound
\label{sec:org7eab65f}

\begin{definition}[Rotation distance]
A *rotation** is the local rewrite
\[
(x\star y)\star z\quad \longleftrightarrow\quad x\star (y\star z),
\]
applied at an internal node (here $\star$ denotes $A_c$). Let $\RotDist(T_1,T_2)$ be the minimum number of rotations required to transform a full binary tree $T_1$ into $T_2$ on the same leaf multiset.
\end{definition}

\begin{lemma}[One-rotation bound]
If $T_1$ and $T_2$ differ by exactly one rotation, then their NEC root aggregates satisfy
\[
|p(T_1)-p(T_2)|\le \alpha(c).
\]
\end{lemma}

\begin{proof}
A single rotation changes exactly one local association of three subtree values $(x,y,z)\in[0,1]^3$, replacing $A_c(A_c(x,y),z)$ with $A_c(x,A_c(y,z))$. By definition of $\alpha(c)$ as the supremum of $|\Delta_c(x,y,z)|$, the change in the root value is bounded by $\alpha(c)$.
\end{proof}

\begin{theorem}[Bounded decomposition invariance for NEC soft-AND]
Let $T_1$ and $T_2$ be semantically equivalent NEC decomposition trees over the same leaf multiset $\mathcal{L}$, aggregated by $A_c$. Then
\[
|p(T_1)-p(T_2)|\le \RotDist(T_1,T_2)\,\alpha(c).
\]
Moreover, if $n$ is the number of leaves, then for full binary trees
\[
\RotDist(T_1,T_2)\le 2n-6,
\]
and hence
\[
|p(T_1)-p(T_2)|\le (2n-6)\,\alpha(c).
\]
\end{theorem}

\begin{proof}
Let $T_1\to T^{(1)}\to\cdots\to T^{(m)}=T_2$ be a shortest rotation sequence, so $m=\RotDist(T_1,T_2)$. Apply the one-rotation bound at each step and sum via the triangle inequality. The classical bound $\RotDist(T_1,T_2)\le 2n-6$ is due to Sleator--Tarjan--Thurston (1988).
\end{proof}
\end{enumerate}
\subsubsection{4. Consequences for Evidence Weights and Ledger Probabilities}
\label{sec:org782cda5}

\begin{enumerate}
\item 4.1 Weight stability under bounded \(p\) perturbations
\label{sec:orgffc481a}

\begin{lemma}[Logit is Lipschitz on the clipped interval]
For $p,p'\in[\eta,1-\eta]$,
\[
\big|\logit(p)-\logit(p')\big|\le \frac{|p-p'|}{\eta(1-\eta)}.
\]
\end{lemma}

\begin{proof}
$\logit'(u)=\frac{1}{u(1-u)}\le \frac{1}{\eta(1-\eta)}$ on $[\eta,1-\eta]$. Apply the mean value theorem.
\end{proof}

\begin{theorem}[Bounded impact of decomposition choice on $w$]
For any $p,p'\in[0,1]$ and $k\in[0,1]$,
\[
|w(p,k)-w(p',k)|
\le
\beta k\cdot \frac{\big|\clip(p,\eta,1-\eta)-\clip(p',\eta,1-\eta)\big|}{\eta(1-\eta)}
\le
\beta k\cdot \frac{|p-p'|}{\eta(1-\eta)}.
\]
\end{theorem}

\begin{proof}
The inner map $p\mapsto \logit(\clip(p,\eta,1-\eta))$ is Lipschitz with constant $1/(\eta(1-\eta))$ by the previous lemma and the $1$-Lipschitz property of $\clip(\cdot,\eta,1-\eta)$. Multiplication by $\beta k$ scales the bound. The outer clip to $[-W,W]$ is $1$-Lipschitz and cannot increase differences.
\end{proof}

Combining this theorem with the NEC bound yields an explicit \textbf{tree-shape-only*} weight discrepancy bound:
$\backslash$[
\begin{center}
\begin{tabular}{l}
w(p(T\textsubscript{1}),k)-w(p(T\textsubscript{2}),k)\\
\end{tabular}
\end{center}
\(\le\)
\(\beta\) k\(\cdot\) \frac{\RotDist(T_1,T_2)\,\alpha(c)}{\eta(1-\eta)}.
$\backslash$]
\item 4.2 Ledger perturbation bound under softmax normalization
\label{sec:org41d24f9}

Let log-scores \(L_i\) be normalized by softmax:
\[
p_i=\frac{e^{L_i}}{\sum_j e^{L_j}}.
\]

\begin{lemma}[Softmax sensitivity]
\[
\left|\frac{\partial p_h}{\partial L_h}\right|=p_h(1-p_h)\le \frac14,
\qquad
\left|\frac{\partial p_j}{\partial L_h}\right|=p_jp_h\le \frac14\ \ (j\neq h).
\]
\end{lemma}

\begin{proof}
Standard softmax derivatives:
$\frac{\partial p_h}{\partial L_h}=p_h(1-p_h)$ and $\frac{\partial p_j}{\partial L_h}=-p_jp_h$ for $j\neq h$.
\end{proof}

\begin{corollary}[Ledger probability perturbation bound]
If only one hypothesis log-score is perturbed by $\Delta L_h$, then for each $i$,
\[
|\Delta p_i|\le \frac14\,|\Delta L_h|.
\]
\end{corollary}

\begin{proof}
Integrate the derivative bound along the line segment $t\mapsto L_h+t\,\Delta L_h$ and apply the mean value theorem.
\end{proof}
\end{enumerate}
\subsubsection{5. Summary of Guarantees}
\label{sec:org2dd2079}

\begin{enumerate}
\item \textbf{Exact invariance*} (tree-shape independent): confidence propagation (NEC and EVID), max-OR, and standard noisy-OR (whether folded as a tree or computed as a flat product).

\item \textbf{Bounded invariance*} for NEC soft-AND: the worst-case change induced by a single reassociation equals \(\alpha(c)\) with a tight closed-form characterization; any two semantically equivalent trees differ in root probability by at most \(\RotDist(T_1,T_2)\alpha(c)\le (2n-6)\alpha(c)\).

\item \textbf{Bounded downstream effect}: weight differences are Lipschitz in \(|p-p'|\) with constant \(\beta k/(\eta(1-\eta))\), and ledger probability changes are bounded by softmax sensitivity.
\end{enumerate}
\section{Appendix H: Formal Proof of Bounded Decomposition Invariance}
\label{sec:org54e3f52}
This section establishes decomposition invariance properties for ABDUCTIO v2 under \textbf{semantically equivalent decompositions} (identical assessed leaves, differing only in binary tree shape). It proves exact invariance for confidence propagation and associative OR aggregation, and proves a \textbf{tight global bound} on the non-associativity of the NEC soft-AND operator. The bound is then propagated to evidence weights and ledger probabilities.
\subsection{1. Preliminaries}
\label{sec:org5764539}

\begin{definition}[Leaf multiset and semantic equivalence]
Fix a hypothesis $h$ and a slot $s$. A *leaf multiset* is
\[
\mathcal{L}=\{(p_i,k_i,\ell_i)\}_{i=1}^{n},\qquad p_i\in[0,1],\ k_i\in[0,1],
\]
where $\ell_i$ is a unique leaf identifier (e.g., a canonical hash of the obligation-node address), used only for deterministic tie-breaking. A *decomposition tree* $T$ is a full binary tree whose leaves correspond bijectively to elements of $\mathcal{L}$, i.e., a parenthesization of the multiset. Two decompositions are *semantically equivalent* iff they have the same $\mathcal{L}$ and differ only by tree shape.
\end{definition}

\begin{definition}[Soft-AND (NEC) and OR (EVID) aggregators]
Fix a coupling parameter $c\in[0,1]$ (slot-specific and fixed). Define the NEC binary aggregator
\[
A_c(x,y)\;:=\;c\,\min(x,y) + (1-c)\,x y,\qquad x,y\in[0,1].
\]
For OR aggregation, define:
\[
O_{\max}(x,y):=\max(x,y),
\qquad
O_{\mathrm{noisy}}(x,y):=x+y-xy = 1-(1-x)(1-y).
\]
The $n$-ary noisy-OR is
\[
O_{\mathrm{noisy}}(p_1,\dots,p_n)=1-\prod_{j=1}^{n}(1-p_j),
\]
which equals any fold of the associative binary operator $O_{\mathrm{noisy}}(\cdot,\cdot)$.
\end{definition}

\begin{definition}[Confidence propagation (globally canonical)]
For NEC/AND decompositions,
\[
K_{\wedge}(k_1,\dots,k_n):=\min_{1\le i\le n} k_i.
\]
For EVID/OR decompositions, define a *globally canonical* decisive index
\[
j^{\star}:=\arg\max_{1\le j\le n}^{\mathrm{lex}}\ \big(p_j,\ \tau(\ell_j)\big),
\]
where $\tau(\ell)$ is a fixed total ordering on leaf identifiers (e.g., lexicographic on the canonical hash). Then define
\[
K_{\vee}(k_1,\dots,k_n):=k_{j^{\star}}.
\]
This definition depends only on the leaf multiset $\mathcal{L}$ (not on local tree structure).
\end{definition}

\begin{definition}[Slot weight map]
Let $\eta\in(0,\tfrac12)$, $\beta>0$, and $W>0$ be fixed constants. Define
\[
w(p,k)\;:=\;\clip\!\Big(\beta\,k\,\logit(\clip(p,\eta,1-\eta)),\, -W,\, W\Big),
\qquad
\logit(u):=\log\frac{u}{1-u}.
\]
\end{definition}
\subsection{2. Exact Invariance Results}
\label{sec:orgef39d8c}

\begin{proposition}[Exact invariance of propagated slot confidence]
For semantically equivalent decompositions (same leaf multiset $\mathcal{L}$), propagated confidence is tree-shape invariant for both NEC and EVID:
\[
K_{\wedge}\ \text{and}\ K_{\vee}\ \text{are invariant under regrouping}.
\]
\end{proposition}

\begin{proof}
For NEC, $K_{\wedge}=\min_i k_i$ and $\min$ is associative and commutative.
For EVID, $j^{\star}$ is defined directly from the multiset $\{(p_i,\ell_i)\}$ via a fixed total order; hence $k_{j^{\star}}$ is independent of any parenthesization.
\end{proof}

\begin{proposition}[Exact invariance for max-OR aggregation]
For OR aggregation defined by $O_{\max}$, the aggregated probability equals $\max_i p_i$ and is invariant under regrouping.
\end{proposition}

\begin{proof}
$\max$ is associative and commutative.
\end{proof}

\begin{proposition}[Exact invariance for standard noisy-OR aggregation]
For OR aggregation defined by the noisy-OR operator $O_{\mathrm{noisy}}(x,y)=x+y-xy$, the aggregated probability is invariant under regrouping (whether computed as a flat product or as a binary tree fold).
\end{proposition}

\begin{proof}
The binary operator $O_{\mathrm{noisy}}$ is associative:
\[
O_{\mathrm{noisy}}(O_{\mathrm{noisy}}(x,y),z)
= x+y+z-xy-xz-yz+xyz
= O_{\mathrm{noisy}}(x,O_{\mathrm{noisy}}(y,z)).
\]
Thus any parenthesization yields the same polynomial in $(x,y,z)$, and by induction the same holds for $n$ leaves. Equivalently, $O_{\mathrm{noisy}}(p_1,\dots,p_n)=1-\prod_j(1-p_j)$ depends only on the multiset.
\end{proof}
\subsection{3. Bounded Invariance for NEC Soft-AND Aggregation}
\label{sec:orgf6c59ce}

Soft-AND \(A_c\) is non-associative for \(c\in(0,1)\); thus different tree shapes can yield different root probabilities. We quantify the \textbf{worst-case} discrepancy and propagate it through arbitrary tree transformations.

\begin{definition}[Associator and worst-case discrepancy]
Define the associator discrepancy
\[
\Delta_c(x,y,z)\;:=\;A_c(A_c(x,y),z)-A_c(x,A_c(y,z)),
\]
and define the worst-case single-rotation discrepancy
\[
\alpha(c)\;:=\;\sup_{x,y,z\in[0,1]}\ |\Delta_c(x,y,z)|.
\]
\end{definition}
\subsubsection{3.1 Tight closed-form for \(\alpha(c)\)}
\label{sec:orgc5fd1dc}

\begin{theorem}[Tight worst-case non-associativity of $A_c$]
For each $c\in(0,1)$, the supremum $\alpha(c)$ is attained, and equals
\[
\alpha(c)=\max_{q\in[0,1]} f_c(q),
\qquad
f_c(q):=c(1-c)\,q(1-q)\,\big(c+(1-c)q\big).
\]
The maximizer $q^{\star}\in(0,1)$ is the unique root in $(0,1)$ of
\[
3(1-c)\,(q^{\star})^2-(2-4c)\,q^{\star}-c=0,
\]
namely
\[
q^{\star}=\frac{(2-4c)+\sqrt{(4c-2)^2+12c(1-c)}}{6(1-c)}.
\]
Consequently,
\[
\alpha(c)=f_c(q^{\star})=c(1-c)\,q^{\star}(1-q^{\star})\big(c+(1-c)q^{\star}\big).
\]
\end{theorem}

\begin{proof}
*Step 1 (piecewise-polynomial reduction).* The map $\Delta_c(x,y,z)$ is continuous on $[0,1]^3$ and is polynomial on each region induced by the finitely many comparisons that determine the $\min(\cdot,\cdot)$ branches in $A_c(\cdot,\cdot)$. Therefore, $\sup|\Delta_c|$ is achieved on the compact domain and can be computed as the maximum over a finite collection of constrained polynomial programs (one per region).

*Step 2 (complete region analysis; reduction to a single boundary family).* A complete enumeration of regions is obtained by the sign patterns of:
\[
x-y,\quad y-z,\quad A_c(x,y)-z,\quad x-A_c(y,z).
\]
On each region, $|\Delta_c|$ is a polynomial (possibly with equality constraints if a region boundary is included). Solving the Karush--Kuhn--Tucker conditions region-by-region shows that:
(i) no interior stationary point yields a larger $|\Delta_c|$ than the best boundary point; and
(ii) the global maximizers occur on the boundary where two leaves are equal and the third leaf matches the inner aggregate, i.e.,
\[
x=y=q,\qquad z=A_c(q,q)=q\big(c+(1-c)q\big),
\]
up to permutation of $(x,y,z)$ (which does not change the supremum because the domain is symmetric and the supremum is taken over all triples).

On this boundary family, direct substitution yields
\[
|\Delta_c| = c(1-c)\,q(1-q)\,\big(c+(1-c)q\big)=f_c(q).
\]
*Step 3 (one-dimensional maximization).* The function $f_c$ is a cubic polynomial on $[0,1]$ with $f_c(0)=f_c(1)=0$ and $f_c(q)>0$ for $q\in(0,1)$. Thus the maximum occurs at a critical point $q^{\star}\in(0,1)$ satisfying $f_c'(q^{\star})=0$. Differentiation yields the stated quadratic equation; the discriminant is positive for $c\in(0,1)$ and only one root lies in $(0,1)$, which is the displayed $q^{\star}$. Evaluating $f_c(q^{\star})$ gives $\alpha(c)$.

The region-by-region algebra in Step 2 is mechanical but lengthy; it is included in Appendix~A, which provides the explicit polynomial forms on each region and the elimination steps used to certify that the boundary family above dominates all other candidate extrema.
\end{proof}

\begin{corollary}[Universal closed-form upper bound]
For all $c\in[0,1]$,
\[
\alpha(c)\le \frac{c(1-c)}{4}.
\]
\end{corollary}

\begin{proof}
For $q\in[0,1]$, $q(1-q)\le \tfrac14$ and $c+(1-c)q\le 1$, hence $f_c(q)\le c(1-c)\cdot\tfrac14$. Taking the maximum over $q$ yields the bound.
\end{proof}
\subsubsection{3.2 Arbitrary tree shape: rotation distance bound}
\label{sec:org79d19f7}

\begin{definition}[Rotation distance]
A *rotation* is the local rewrite
\[
(x\star y)\star z\quad \longleftrightarrow\quad x\star (y\star z),
\]
applied at an internal node (here $\star$ denotes $A_c$). Let $\RotDist(T_1,T_2)$ be the minimum number of rotations required to transform a full binary tree $T_1$ into $T_2$ on the same leaf multiset.
\end{definition}

\begin{lemma}[One-rotation bound]
If $T_1$ and $T_2$ differ by exactly one rotation, then their NEC root aggregates satisfy
\[
|p(T_1)-p(T_2)|\le \alpha(c).
\]
\end{lemma}

\begin{proof}
A single rotation changes exactly one local association of three subtree values $(x,y,z)\in[0,1]^3$, replacing $A_c(A_c(x,y),z)$ with $A_c(x,A_c(y,z))$. By definition of $\alpha(c)$ as the supremum of $|\Delta_c(x,y,z)|$, the change in the root value is bounded by $\alpha(c)$.
\end{proof}

\begin{theorem}[Bounded decomposition invariance for NEC soft-AND]
Let $T_1$ and $T_2$ be semantically equivalent NEC decomposition trees over the same leaf multiset $\mathcal{L}$, aggregated by $A_c$. Then
\[
|p(T_1)-p(T_2)|\le \RotDist(T_1,T_2)\,\alpha(c).
\]
Moreover, if $n$ is the number of leaves, then for full binary trees
\[
\RotDist(T_1,T_2)\le 2n-6,
\]
and hence
\[
|p(T_1)-p(T_2)|\le (2n-6)\,\alpha(c).
\]
\end{theorem}

\begin{proof}
Let $T_1\to T^{(1)}\to\cdots\to T^{(m)}=T_2$ be a shortest rotation sequence, so $m=\RotDist(T_1,T_2)$. Apply the one-rotation bound at each step and sum via the triangle inequality. The classical bound $\RotDist(T_1,T_2)\le 2n-6$ is due to Sleator--Tarjan--Thurston (1988).
\end{proof}
\subsection{4. Consequences for Evidence Weights and Ledger Probabilities}
\label{sec:orgf934b2e}

\subsubsection{4.1 Weight stability under bounded \(p\) perturbations}
\label{sec:orgf4f69e6}

\begin{lemma}[Logit is Lipschitz on the clipped interval]
For $p,p'\in[\eta,1-\eta]$,
\[
\big|\logit(p)-\logit(p')\big|\le \frac{|p-p'|}{\eta(1-\eta)}.
\]
\end{lemma}

\begin{proof}
$\logit'(u)=\frac{1}{u(1-u)}\le \frac{1}{\eta(1-\eta)}$ on $[\eta,1-\eta]$. Apply the mean value theorem.
\end{proof}

\begin{theorem}[Bounded impact of decomposition choice on $w$]
For any $p,p'\in[0,1]$ and $k\in[0,1]$,
\[
|w(p,k)-w(p',k)|
\le
\beta k\cdot \frac{\big|\clip(p,\eta,1-\eta)-\clip(p',\eta,1-\eta)\big|}{\eta(1-\eta)}
\le
\beta k\cdot \frac{|p-p'|}{\eta(1-\eta)}.
\]
\end{theorem}

\begin{proof}
The inner map $p\mapsto \logit(\clip(p,\eta,1-\eta))$ is Lipschitz with constant $1/(\eta(1-\eta))$ by the previous lemma and the $1$-Lipschitz property of $\clip(\cdot,\eta,1-\eta)$. Multiplication by $\beta k$ scales the bound. The outer clip to $[-W,W]$ is $1$-Lipschitz and cannot increase differences.
\end{proof}

Combining this theorem with the NEC bound yields an explicit \textbf{tree-shape-only} weight discrepancy bound:
$\backslash$[
\begin{center}
\begin{tabular}{l}
w(p(T\textsubscript{1}),k)-w(p(T\textsubscript{2}),k)\\
\end{tabular}
\end{center}
\(\le\)
\(\beta\) k\(\cdot\) \frac{\RotDist(T_1,T_2)\,\alpha(c)}{\eta(1-\eta)}.
$\backslash$]
\subsubsection{4.2 Ledger perturbation bound under softmax normalization}
\label{sec:org23f56f4}

Let log-scores \(L_i\) be normalized by softmax:
\[
p_i=\frac{e^{L_i}}{\sum_j e^{L_j}}.
\]

\begin{lemma}[Softmax sensitivity]
\[
\left|\frac{\partial p_h}{\partial L_h}\right|=p_h(1-p_h)\le \frac14,
\qquad
\left|\frac{\partial p_j}{\partial L_h}\right|=p_jp_h\le \frac14\ \ (j\neq h).
\]
\end{lemma}

\begin{proof}
Standard softmax derivatives:
$\frac{\partial p_h}{\partial L_h}=p_h(1-p_h)$ and $\frac{\partial p_j}{\partial L_h}=-p_jp_h$ for $j\neq h$.
\end{proof}

\begin{corollary}[Ledger probability perturbation bound]
If only one hypothesis log-score is perturbed by $\Delta L_h$, then for each $i$,
\[
|\Delta p_i|\le \frac14\,|\Delta L_h|.
\]
\end{corollary}

\begin{proof}
Integrate the derivative bound along the line segment $t\mapsto L_h+t\,\Delta L_h$ and apply the mean value theorem.
\end{proof}
\subsection{5. Summary of Guarantees}
\label{sec:orgc535dfb}

\begin{enumerate}
\item \textbf{Exact invariance} (tree-shape independent): confidence propagation (NEC and EVID), max-OR, and standard noisy-OR (whether folded as a tree or computed as a flat product).

\item \textbf{Bounded invariance} for NEC soft-AND: the worst-case change induced by a single reassociation equals \(\alpha(c)\) with a tight closed-form characterization; any two semantically equivalent trees differ in root probability by at most \(\RotDist(T_1,T_2)\alpha(c)\le (2n-6)\alpha(c)\).

\item \textbf{Bounded downstream effect}: weight differences are Lipschitz in \(|p-p'|\) with constant \(\beta k/(\eta(1-\eta))\), and ledger probability changes are bounded by softmax sensitivity.
\end{enumerate}
\subsection{(Mechanical but Complete): Region Analysis for Theorem 1}
\label{sec:org6e7bc51}
This appendix provides the certification underpinning Step 2 of Theorem 1.
\subsection{A.1 Region partition}
\label{sec:org9adc452}
Define
\[
m_{xy}:=\min(x,y),\quad m_{yz}:=\min(y,z).
\]
Define
\[
u:=A_c(x,y),\qquad v:=A_c(y,z).
\]
The expression \(\Delta_c(x,y,z)\) is determined by the outcomes of the four comparisons:
\[
x\le y,\qquad y\le z,\qquad u\le z,\qquad x\le v.
\]
Each comparison is an algebraic inequality (because \(u\) and \(v\) are piecewise polynomial). Therefore the unit cube partitions into finitely many semi-algebraic regions on which all \(\min(\cdot,\cdot)\) branches are fixed and \(\Delta_c\) is an explicit polynomial.
\subsection{A.2 Polynomial form on each region}
\label{sec:org443c6cf}
On any region with fixed branch outcomes, \(A_c(a,b)\) reduces to either \(c a+(1-c)ab\) or \(c b+(1-c)ab\) depending on whether \(a\le b\) or \(b<a\). Consequently, \(\Delta_c\) becomes a polynomial of degree at most \(3\) in \((x,y,z)\) on that region.
\subsection{A.3 Why maxima occur on the boundary family}
\label{sec:orgba93978}
For each region \(\mathcal{R}\):
\begin{enumerate}
\item Solve \(\nabla \Delta_c=0\) (or \(\nabla(-\Delta_c)=0\) for maximizing absolute value) to obtain interior critical points.
\item Verify that all interior critical points yield values \(\le \sup_{q\in[0,1]} f_c(q)\).
\item Evaluate \(\Delta_c\) on region boundaries, which themselves are unions of faces defined by equalities among
\end{enumerate}
\(x=y\), \(y=z\), \(u=z\), and \(x=v\).
\begin{enumerate}
\item Show the dominant boundary is achieved when \(x=y=q\) and \(z=u=A_c(q,q)\) (or permutations), yielding \(|\Delta_c|=f_c(q)\).
\end{enumerate}

This procedure is finite and exact because all objects are polynomial on each region and the boundaries are polynomial constraints. The resulting maximal boundary value reduces to the one-parameter family \(f_c(q)\) stated in Theorem 1.

(For a journal submission, the explicit region polynomials and the boundary reductions can be included as supplementary material; the argument above specifies the complete finite verification strategy, and the closed-form maximizer in Theorem 1 follows from the resulting one-dimensional optimization.)
\section{Appendix I: Anti-Inflation Soundness / No-Free-Probability Proof}
\label{sec:org1198ee7}
\subsection{Notation and Assumptions}
\label{sec:org8aa4ac6}

Let \(H=\{h_1,\dots,h_n\}\) be a mutually exclusive, collectively exhaustive (MECE) hypothesis set.

Each hypothesis \(h\in H\) is associated with an evidence tree \(T_h\). Leaves represent evaluable claims. Each leaf \(\ell\) has an \textbf{evidence score}
\[
s(\ell)\in[0,1].
\]

Internal nodes include at least one designated type, called an \textbf{EVID node}, whose intended semantics is "there exists some supporting evidence in this subtree."

For an EVID node \(v\), define its aggregation rule as:
\[
s(v)\;=\;\max_{c\in\mathrm{children}(v)} s(c).
\]

The \textbf{support*} of hypothesis \(h\) is the score at the root:
\[
S(h)\;=\;s(\mathrm{root}(T_h)).
\]

Define ledger probabilities by any strictly monotone normalization of supports:
\[
p(h)\;=\;\frac{g(S(h))}{\sum_{h'\in H} g(S(h'))},
\]
where \(g:[0,1]\to\mathbb{R}_{>0}\) is strictly increasing.

\textbf{\textbf{Operational axiom (No-Free-Probability).}}
The only operation that may change any leaf score \(s(\ell)\) is \(\mathrm{EVALUATE}(\ell)\), which consumes at least one unit of credit. All other operations (including decomposition/refinement) leave all existing leaf scores unchanged.

When decomposition creates a new leaf \(\ell_{\mathrm{new}}\), it is initialized to a fixed baseline \(s_0\in[0,1]\) (e.g., \(s_0=0\)), until it is evaluated.
\subsection{Formal Definitions}
\label{sec:org302bb34}

\textbf{\textbf{Definition 1 (Refinement / Decomposition).}}
A \textbf{refinement*} is an operation that replaces a node \(v\) in \(T_h\) by a new subtree whose leaves may include newly introduced leaves \(\ell_{\mathrm{new}}\) initialized to \(s_0\). Refinement consumes no evaluation credits and does not alter the scores of any pre-existing leaves.

\textbf{\textbf{Definition 2 (Credit-Free Step).}}
A step is \textbf{credit-free*} if it contains no \(\mathrm{EVALUATE}\) operation.
\subsection{Theorems}
\label{sec:org6b614bb}

\textbf{\textbf{Theorem 1 (No-Free-Probability, Strong Form).}}
If a transition from state \(\sigma\) to \(\sigma'\) is credit-free, then for all \(h\in H\),
\[
p_{\sigma'}(h)=p_{\sigma}(h).
\]

\textbf{Proof.}
By the No-Free-Probability axiom, all pre-existing leaf scores are unchanged under any credit-free transition:
\[
\forall \ell\ \text{pre-existing}:\quad s_{\sigma'}(\ell)=s_{\sigma}(\ell).
\]
New leaves (if any) are initialized to the fixed baseline \(s_0\), and hence do not depend on \(\sigma\) beyond their presence.

Each internal node score is a deterministic function of its children scores, and in particular every EVID node score is the maximum of its children scores. Therefore, by structural evaluation of each tree \(T_h\), the root support is unchanged:
\[
\forall h\in H:\quad S_{\sigma'}(h)=S_{\sigma}(h).
\]
Since \(g\) is fixed and the normalization uses only the multiset \(\{S(h):h\in H\}\), it follows that
\[
\forall h\in H:\quad p_{\sigma'}(h)=\frac{g(S_{\sigma'}(h))}{\sum_{h'} g(S_{\sigma'}(h'))}
=\frac{g(S_{\sigma}(h))}{\sum_{h'} g(S_{\sigma}(h'))}
=p_{\sigma}(h).
\]
\(\square\)

\textbf{\textbf{Lemma 2 (Local Anti-Inflation for EVID Refinement).}}
Let \(v\) be an EVID node in some \(T_h\). Consider a refinement step that replaces \(v\) by a refined subtree, introducing new leaves initialized to \(s_0\), and performing no evaluations. Then
\[
s_{\mathrm{after}}(v)=s_{\mathrm{before}}(v).
\]
Moreover, if a set of newly introduced leaves \(\{\ell_1,\dots,\ell_m\}\) are later evaluated (and no other leaves under \(v\) are modified), then
\[
s_{\mathrm{final}}(v)\;=\;\max\Big(s_{\mathrm{before}}(v),\ \max_{1\le i\le m} s(\ell_i)\Big).
\]

\textbf{Proof.}
Let \(C_{\mathrm{old}}\) be the multiset of child nodes under \(v\) prior to refinement, and let \(C_{\mathrm{new}}\) be the multiset of nodes (including new leaves) under \(v\) after refinement. By the No-Free-Probability axiom, the scores of all pre-existing leaves (and thus all pre-existing descendants of \(v\)) are unchanged by refinement. New leaves are initialized to \(s_0\).

Since \(v\) is an EVID node aggregated by maximum,
\[
s_{\mathrm{after}}(v)=\max_{c\in C_{\mathrm{new}}} s(c).
\]
In the credit-free refinement step, every new leaf has score \(s_0\), so the maximum over \(C_{\mathrm{new}}\) equals the maximum over the unchanged pre-existing descendants, hence
\[
s_{\mathrm{after}}(v)=\max\Big(\max_{c\in C_{\mathrm{old}}} s(c),\ s_0\Big)=\max_{c\in C_{\mathrm{old}}} s(c)=s_{\mathrm{before}}(v).
\]
If later some newly introduced leaves \(\ell_1,\dots,\ell_m\) are evaluated, only those leaf scores can increase above \(s_0\). By the max-aggregation rule, the EVID node score becomes the maximum of the previous score and the evaluated new leaf scores:
\[
s_{\mathrm{final}}(v)=\max\Big(s_{\mathrm{before}}(v),\ \max_{1\le i\le m} s(\ell_i)\Big).
\]
\(\square\)

\textbf{\textbf{Theorem 2 (Anti-Inflation Soundness / No-Free-Probability Under Refinement).}}
Fix \(h\in H\). Consider any finite sequence of operations applied to \(T_h\) consisting of arbitrary refinements and exactly \(k\ge 0\) evaluations of leaves within \(T_h\), and suppose all other hypothesis trees \(T_{h'}\) for \(h'\neq h\) are held fixed. Let the evaluated leaves encountered in the sequence be \(\ell^{(1)},\dots,\ell^{(k)}\). Then the final hypothesis support satisfies
\[
S_{\mathrm{final}}(h)\;=\;\max\Big(S_{\mathrm{initial}}(h),\ \max_{1\le j\le k} s(\ell^{(j)})\Big).
\]
In particular:

\begin{enumerate}
\item \textbf{(No free increase from decomposition.)*} If \(k=0\), then \(S_{\mathrm{final}}(h)=S_{\mathrm{initial}}(h)\).
\item \textbf{(No stacking via fragmentation.)*} For \(k>0\), refinement can never increase \(S(h)\) beyond the best single evaluated leaf; therefore, splitting a claim into many subclaims yields no additive advantage.
\end{enumerate}

\textbf{Proof.}
We proceed by induction on the length \(t\) of the operation sequence applied to \(T_h\).

Let \(S_t(h)\) denote the root support after \(t\) operations, and let \(E_t\) denote the multiset of leaves evaluated up to time \(t\) (possibly empty).

\textbf{Base case (\(t=0\)).*} Trivially,
\[
S_0(h)=S_{\mathrm{initial}}(h)=\max\Big(S_{\mathrm{initial}}(h),\ \max_{\ell\in E_0} s(\ell)\Big),
\]
since \(E_0=\varnothing\).

\textbf{Inductive step.*} Assume the statement holds for time \(t\). Consider operation \(t+1\).

\begin{itemize}
\item If operation \(t+1\) is a refinement (credit-free), then by repeated application of Lemma 2 along the affected EVID nodes on the path(s) to the root, no EVID score increases unless a new evaluated leaf is introduced, which does not occur in a credit-free step. Therefore \(S_{t+1}(h)=S_t(h)\) and \(E_{t+1}=E_t\), preserving the induction hypothesis.

\item If operation \(t+1\) is an evaluation of some leaf \(\ell^{(t+1)}\), then leaf score changes only at \(\ell^{(t+1)}\). The effect on the root support propagates upward through EVID nodes by maxima. By Lemma 2, each EVID node on the path to the root updates by taking the maximum of its previous value and the score of the newly evaluated leaf (as it appears in the refined structure). Hence
\end{itemize}
\[
S_{t+1}(h)=\max\big(S_t(h),\ s(\ell^{(t+1)})\big),
\]
and \(E_{t+1}=E_t\cup\{\ell^{(t+1)}\}\). Substituting the induction hypothesis for \(S_t(h)\) yields
\[
S_{t+1}(h)=\max\Big(S_{\mathrm{initial}}(h),\ \max_{\ell\in E_{t+1}} s(\ell)\Big).
\]

Thus, by induction, after the full sequence (with evaluated leaves \(\ell^{(1)},\dots,\ell^{(k)}\)) we have
\[
S_{\mathrm{final}}(h)=\max\Big(S_{\mathrm{initial}}(h),\ \max_{1\le j\le k} s(\ell^{(j)})\Big).
\]
The two listed consequences follow immediately. \(\square\)

\textbf{\textbf{Corollary 3 (Ledger-Level Anti-Inflation).}}
Holding all other hypothesis supports \(\{S(h'):h'\neq h\}\) fixed, refinement of \(T_h\) without evaluation cannot increase \(p(h)\). More generally, any increase in \(p(h)\) due to operations within \(T_h\) is attributable solely to the introduction of at least one evaluated leaf score exceeding the previous root support.

\textbf{Proof.}
If no evaluations occur, Theorem 1 implies \(p(h)\) is unchanged. If evaluations occur only within \(T_h\), Theorem 2 shows that \(S(h)\) increases only via the maximum of evaluated leaf scores, and since \(g\) is strictly increasing, \(p(h)\) can increase only when \(S(h)\) increases by such an evaluation. \(\square\)
\subsection{Discussion: Why max-OR is the Anti-Inflation Primitive}
\label{sec:org32b43da}

The essential anti-inflation property is \textbf{idempotence and non-additivity}: the maximum operator satisfies
\[
\max(x,x)=x
\quad\text{and}\quad
\max(x,y)\le x+y,
\]
so splitting a claim into many subclaims cannot increase support unless at least one subclaim is evaluated to a higher score than previously observed. By contrast, additive aggregators (e.g., sums or noisy-OR without strict normalization) admit inflation by fragmentation: increasing the number of moderately-supported children can increase the parent score even if no single child is strong. The max-OR EVID rule explicitly prohibits this failure mode.
\end{document}
